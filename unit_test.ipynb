{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6JcB5cgAyNBW",
   "metadata": {
    "id": "6JcB5cgAyNBW"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "JBzYdW9LF-pT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29108,
     "status": "ok",
     "timestamp": 1756874156265,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "JBzYdW9LF-pT",
    "outputId": "5f94e5e5-d57f-4365-f6d0-29316ff51386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\homepage\\jupyter_hangul\n",
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\homepage\\jupyter_hangul\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'helper_c0z0c_dev' from 'd:\\\\GoogleDrive\\\\homepage\\\\jupyter_hangul\\\\helper_c0z0c_dev.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n",
    "import importlib\n",
    "import helper_c0z0c_dev as helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "W-2oOWLbF_XV",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1756874159267,
     "user": {
      "displayName": "dev c0z0c",
      "userId": "08071297324787696567"
     },
     "user_tz": -540
    },
    "id": "W-2oOWLbF_XV"
   },
   "outputs": [],
   "source": [
    "import helper_c0z0c_dev as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-ku2ZIbgyLEN",
   "metadata": {
    "id": "-ku2ZIbgyLEN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒŒì¼ ì¡´ì¬: True\n",
      "pandas ì§ì ‘ ì½ê¸° ì„±ê³µ: (3, 4)\n",
      "ì»¬ëŸ¼: ['ì´ë¦„', 'ë‚˜ì´', 'ì§ì—…', 'ì—°ë´‰']\n",
      "ì²« ë²ˆì§¸ í–‰ ë°ì´í„°: {'ì´ë¦„': 'ê¹€ì² ìˆ˜', 'ë‚˜ì´': 25, 'ì§ì—…': 'ê°œë°œì', 'ì—°ë´‰': 4000}\n"
     ]
    }
   ],
   "source": [
    "# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¡œ ë¬¸ì œ í™•ì¸\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "test_file = \"data/test_sample.csv\"\n",
    "print(f\"íŒŒì¼ ì¡´ì¬: {os.path.exists(test_file)}\")\n",
    "\n",
    "# pandasë¡œ ì§ì ‘ ì½ê¸°\n",
    "if os.path.exists(test_file):\n",
    "    df = pd.read_csv(test_file)\n",
    "    print(f\"pandas ì§ì ‘ ì½ê¸° ì„±ê³µ: {df.shape}\")\n",
    "    print(f\"ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "\n",
    "    # helper ì—†ì´ ë‹¨ìˆœ í…ŒìŠ¤íŠ¸\n",
    "    print(f\"ì²« ë²ˆì§¸ í–‰ ë°ì´í„°: {df.iloc[0].to_dict()}\")\n",
    "else:\n",
    "    print(\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87095d0d",
   "metadata": {
    "id": "87095d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n",
      "ğŸ“Œ ì´ í•¨ìˆ˜ë“¤ì€ 15ë²ˆ ì…€ì˜ run_test í•¨ìˆ˜ ì •ì˜ í›„ì— ì‹¤í–‰ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "def test_pd_read_csv_local_file():\n",
    "    \"\"\"ë¡œì»¬ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ“ ë¡œì»¬ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    # ì •ìƒì ì¸ íŒŒì¼ ì½ê¸°\n",
    "    df = helper.pd_read_csv(test_csv_file)\n",
    "\n",
    "    if df is not None:\n",
    "        print(f\"âœ… íŒŒì¼ ì½ê¸° ì„±ê³µ: {df.shape}\")\n",
    "        print(f\"ğŸ“Š ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "        # ì‹¤ì œ íŒŒì¼ì€ 4í–‰ 4ì—´ì…ë‹ˆë‹¤ (í—¤ë” ì œì™¸ 3í–‰ ë°ì´í„°)\n",
    "        assert df.shape[0] == 3, f\"í–‰ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ: ì˜ˆìƒ 3, ì‹¤ì œ {df.shape[0]}\"\n",
    "        assert df.shape[1] == 4, f\"ì—´ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ: ì˜ˆìƒ 4, ì‹¤ì œ {df.shape[1]}\"\n",
    "        assert 'ì´ë¦„' in df.columns, \"'ì´ë¦„' ì»¬ëŸ¼ì´ ì—†ìŒ\"\n",
    "        return df\n",
    "    else:\n",
    "        raise Exception(\"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨\")\n",
    "\n",
    "def test_pd_read_csv_with_options():\n",
    "    \"\"\"ì˜µì…˜ì„ í¬í•¨í•œ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"âš™ï¸ ì˜µì…˜ í¬í•¨ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    # ì‹¤ì œ íŒŒì¼ì˜ ì»¬ëŸ¼ëª…ì— ë§ì¶° íŠ¹ì • ì»¬ëŸ¼ë§Œ ì½ê¸°\n",
    "    df = helper.pd_read_csv(test_csv_file, usecols=['ì´ë¦„', 'ë‚˜ì´'])\n",
    "\n",
    "    if df is not None:\n",
    "        print(f\"âœ… ì˜µì…˜ ì ìš© ì„±ê³µ: {df.shape}\")\n",
    "        print(f\"ğŸ“Š ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "        assert df.shape[1] == 2, \"ì»¬ëŸ¼ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ\"\n",
    "        assert set(df.columns) == {'ì´ë¦„', 'ë‚˜ì´'}, \"ì»¬ëŸ¼ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ\"\n",
    "        return df\n",
    "    else:\n",
    "        raise Exception(\"ì˜µì…˜ ì ìš© íŒŒì¼ ì½ê¸° ì‹¤íŒ¨\")\n",
    "\n",
    "def test_pd_read_csv_stringio():\n",
    "    \"\"\"StringIO ê°ì²´ë¡œ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ“ StringIO ê°ì²´ ì½ê¸° í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    csv_string = \"id,name,score\\n1,í…ŒìŠ¤íŠ¸,100\\n2,ì‚¬ìš©ì,95\"\n",
    "    string_io = StringIO(csv_string)\n",
    "\n",
    "    df = helper.pd_read_csv(string_io)\n",
    "\n",
    "    if df is not None:\n",
    "        print(f\"âœ… StringIO ì½ê¸° ì„±ê³µ: {df.shape}\")\n",
    "        print(f\"ğŸ“Š ë°ì´í„°:\\n{df}\")\n",
    "        assert df.shape[0] == 2, \"í–‰ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ\"\n",
    "        assert df.shape[1] == 3, \"ì—´ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ\"\n",
    "        return df\n",
    "    else:\n",
    "        raise Exception(\"StringIO ì½ê¸° ì‹¤íŒ¨\")\n",
    "\n",
    "def test_pd_read_csv_url_detection():\n",
    "    \"\"\"URL ê°ì§€ ë¡œì§ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸŒ URL ê°ì§€ ë¡œì§ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    test_urls = [\n",
    "        \"https://example.com/data.csv\",\n",
    "        \"http://example.com/data.csv\",\n",
    "        \"ftp://ftp.example.com/data.csv\",\n",
    "        \"file:///path/to/data.csv\"\n",
    "    ]\n",
    "\n",
    "    for url in test_urls:\n",
    "        is_url = url.startswith(('http://', 'https://', 'ftp://', 'file://'))\n",
    "        print(f\"ğŸ”— {url} â†’ URL: {is_url}\")\n",
    "        assert is_url == True, f\"URL ê°ì§€ ì‹¤íŒ¨: {url}\"\n",
    "\n",
    "    # ì¼ë°˜ íŒŒì¼ëª…ì€ URLì´ ì•„ë‹˜\n",
    "    normal_files = [\"data.csv\", \"./data.csv\", \"/absolute/path/data.csv\"]\n",
    "    for file in normal_files:\n",
    "        is_url = file.startswith(('http://', 'https://', 'ftp://', 'file://'))\n",
    "        print(f\"ğŸ“ {file} â†’ URL: {is_url}\")\n",
    "        assert is_url == False, f\"íŒŒì¼ëª… URL ê°ì§€ ì˜¤ë¥˜: {file}\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_pd_read_csv_file_not_found():\n",
    "    \"\"\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸš« ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    df = helper.pd_read_csv(\"nonexistent_file.csv\")\n",
    "\n",
    "    if df is None:\n",
    "        print(\"âœ… ì˜ˆìƒëŒ€ë¡œ None ë°˜í™˜\")\n",
    "        return True\n",
    "    else:\n",
    "        raise Exception(\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ì—ì„œ ë°ì´í„°ê°€ ë°˜í™˜ë¨\")\n",
    "\n",
    "def test_pd_read_csv_environment_path():\n",
    "    \"\"\"í™˜ê²½ë³„ ê²½ë¡œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸŒ í™˜ê²½ë³„ ê²½ë¡œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    # í˜„ì¬ ì„¤ì •ëœ pd_root í™•ì¸\n",
    "    current_root = helper.pd_root()\n",
    "    print(f\"ğŸ“ í˜„ì¬ pd_root: {current_root}\")\n",
    "\n",
    "    # ìƒëŒ€ ê²½ë¡œë¡œ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\n",
    "    if helper.is_colab:\n",
    "        # Colabì—ì„œëŠ” ì ˆëŒ€ ê²½ë¡œë¡œ í…ŒìŠ¤íŠ¸\n",
    "        relative_path = \"homepage/jupyter_hangul/data/test_sample.csv\"\n",
    "        helper.set_pd_root_base(\"homepage/jupyter_hangul\")\n",
    "    else:\n",
    "        # ë¡œì»¬ì—ì„œëŠ” ìƒëŒ€ ê²½ë¡œë¡œ í…ŒìŠ¤íŠ¸ - ì‹¤ì œ íŒŒì¼ëª… ì‚¬ìš©\n",
    "        relative_path = \"data/test_sample.csv\"\n",
    "        helper.set_pd_root_base(\".\")\n",
    "\n",
    "    df = helper.pd_read_csv(relative_path)\n",
    "\n",
    "    if df is not None:\n",
    "        print(f\"âœ… í™˜ê²½ë³„ ê²½ë¡œ ì²˜ë¦¬ ì„±ê³µ: {df.shape}\")\n",
    "        print(f\"ğŸ“Š ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "        # ì‹¤ì œ íŒŒì¼ ê²€ì¦\n",
    "        assert 'ì´ë¦„' in df.columns, \"ì‹¤ì œ íŒŒì¼ì˜ ì»¬ëŸ¼ì´ í™•ì¸ë˜ì§€ ì•ŠìŒ\"\n",
    "        return True\n",
    "    else:\n",
    "        raise Exception(\"í™˜ê²½ë³„ ê²½ë¡œ ì²˜ë¦¬ ì‹¤íŒ¨\")\n",
    "\n",
    "def test_pd_read_csv_created_file():\n",
    "    \"\"\"ìƒì„±ëœ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ“„ ìƒì„±ëœ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ìƒì„±í•œ íŒŒì¼ ì½ê¸° (ì˜ë¬¸ ì»¬ëŸ¼ëª…)\n",
    "    df = helper.pd_read_csv(test_csv_create_file)\n",
    "\n",
    "    if df is not None:\n",
    "        print(f\"âœ… ìƒì„±ëœ íŒŒì¼ ì½ê¸° ì„±ê³µ: {df.shape}\")\n",
    "        print(f\"ğŸ“Š ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "        assert df.shape[0] == 5, \"ìƒì„±ëœ íŒŒì¼ì˜ í–‰ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ\"\n",
    "        assert df.shape[1] == 4, \"ìƒì„±ëœ íŒŒì¼ì˜ ì—´ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ\"\n",
    "        assert 'name' in df.columns, \"'name' ì»¬ëŸ¼ì´ ì—†ìŒ\"\n",
    "        return df\n",
    "    else:\n",
    "        raise Exception(\"ìƒì„±ëœ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨\")\n",
    "\n",
    "print(\"ğŸ“‚ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"ğŸ“Œ ì´ í•¨ìˆ˜ë“¤ì€ 15ë²ˆ ì…€ì˜ run_test í•¨ìˆ˜ ì •ì˜ í›„ì— ì‹¤í–‰ë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0d029b",
   "metadata": {
    "id": "4c0d029b"
   },
   "source": [
    "# ğŸ§ª Helper ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸\n",
    "ì´ ë…¸íŠ¸ë¶ì€ helper_c0z0c_dev.pyì˜ ì£¼ìš” ê¸°ëŠ¥ì„ ê·¸ë£¹ë³„ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê° í…ŒìŠ¤íŠ¸ëŠ” í•œê¸€ë¡œ ì„¤ëª…ë˜ë©°, ê·¸ë£¹ë³„ë¡œ ê²°ê³¼ê°€ ëª…í™•íˆ êµ¬ë¶„ë˜ì–´ ë³´ê³ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96072848",
   "metadata": {
    "id": "96072848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ https://c0z0c.github.io/jupyter_hangul\n",
      "âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n",
      "pd commit ì €ì¥ ê²½ë¡œ = d:\\GoogleDrive\\homepage\\jupyter_hangul\n",
      "ëª¨ë“ˆ ë¡œë“œ ë° ì¬ë¡œë“œ ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "# helper ëª¨ë“ˆ ì„í¬íŠ¸ ë° ì¬ë¡œë“œ\n",
    "import importlib\n",
    "import helper_c0z0c_dev as helper\n",
    "importlib.reload(helper)\n",
    "print('ëª¨ë“ˆ ë¡œë“œ ë° ì¬ë¡œë“œ ì„±ê³µ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24121af",
   "metadata": {
    "id": "c24121af"
   },
   "source": [
    "## 1. ê¸°ë³¸ í™˜ê²½ ë° ëª¨ë“ˆ ë¡œë“œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad8fe2",
   "metadata": {
    "id": "d0ad8fe2"
   },
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from io import StringIO\n",
    "import sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸš€ Unit Test Suite ì‹œì‘\")\n",
    "print(f\"ğŸ“… í…ŒìŠ¤íŠ¸ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ Python ë²„ì „: {sys.version}\")\n",
    "print(f\"ğŸ“Š Pandas ë²„ì „: {pd.__version__}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì‹¤ì œ íŒŒì¼ ë°ì´í„° í™•ì¸\n",
    "print(\"\\nğŸ” ì‹¤ì œ íŒŒì¼ ë°ì´í„° í™•ì¸:\")\n",
    "test_file_path = \"data/test_sample.csv\"\n",
    "if os.path.exists(test_file_path):\n",
    "    df_actual = pd.read_csv(test_file_path)\n",
    "    print(f\"ğŸ“Š pandas ì§ì ‘ ì½ê¸° shape: {df_actual.shape}\")\n",
    "    print(f\"ğŸ“‹ pandas ì§ì ‘ ì½ê¸° ì»¬ëŸ¼: {list(df_actual.columns)}\")\n",
    "\n",
    "    # helper.pd_read_csvë¡œ ì½ê¸°\n",
    "    df_helper = helper.pd_read_csv(test_file_path)\n",
    "    print(f\"\udcca helper.pd_read_csv shape: {df_helper.shape}\")\n",
    "    print(f\"ğŸ“‹ helper.pd_read_csv ì»¬ëŸ¼: {list(df_helper.columns)}\")\n",
    "\n",
    "    # ë‘ ê²°ê³¼ê°€ ë™ì¼í•œì§€ í™•ì¸\n",
    "    print(f\"ğŸ” ë‘ ê²°ê³¼ê°€ ë™ì¼í•œê°€? {df_actual.equals(df_helper)}\")\n",
    "\n",
    "    if not df_actual.equals(df_helper):\n",
    "        print(\"âš ï¸ helper.pd_read_csvì™€ pandas.read_csv ê²°ê³¼ê°€ ë‹¤ë¦…ë‹ˆë‹¤!\")\n",
    "        print(\"ì°¨ì´ì  ë¶„ì„:\")\n",
    "        print(f\"  - pandas shape: {df_actual.shape}, helper shape: {df_helper.shape}\")\n",
    "        print(f\"  - pandas dtypes: {df_actual.dtypes.to_dict()}\")\n",
    "        print(f\"  - helper dtypes: {df_helper.dtypes.to_dict()}\")\n",
    "\n",
    "else:\n",
    "    print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_file_path}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XLMsCP3TGjyw",
   "metadata": {
    "id": "XLMsCP3TGjyw"
   },
   "outputs": [],
   "source": [
    "helper.__font_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b509cc84",
   "metadata": {
    "id": "b509cc84"
   },
   "outputs": [],
   "source": [
    "# Helper ëª¨ë“ˆ ë¡œë“œ ìƒíƒœ í™•ì¸\n",
    "print(\"ğŸ” Helper ëª¨ë“ˆ ìƒíƒœ í™•ì¸:\")\n",
    "print(f\"âœ… helper ëª¨ë“ˆ: {helper}\")\n",
    "print(f\"ğŸ“„ ëª¨ë“ˆ ê²½ë¡œ: {helper.__file__ if hasattr(helper, '__file__') else 'Built-in'}\")\n",
    "print(f\"ğŸŒ Colab í™˜ê²½: {helper.is_colab}\")\n",
    "print(f\"ğŸ¨ í°íŠ¸ ê²½ë¡œ: {helper.__font_path if not helper.is_colab else ''}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4044bd7c",
   "metadata": {
    "id": "4044bd7c"
   },
   "source": [
    "## 2. ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b3817",
   "metadata": {
    "id": "c88b3817"
   },
   "outputs": [],
   "source": [
    "# ìºì‹œ ì €ì¥, ë¡œë“œ, ì‚­ì œ í…ŒìŠ¤íŠ¸\n",
    "key = helper.cache_key('í…ŒìŠ¤íŠ¸', 123)\n",
    "helper.cache_save(key, {'a': 1, 'b': 2})\n",
    "print('ìºì‹œ ì €ì¥:', helper.cache_exists(key))\n",
    "print('ìºì‹œ ë¡œë“œ:', helper.cache_load(key))\n",
    "helper.cache_delete(key)\n",
    "print('ìºì‹œ ì‚­ì œ í›„ ì¡´ì¬:', helper.cache_exists(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d1125f",
   "metadata": {
    "id": "f9d1125f"
   },
   "source": [
    "## 3. pandas í™•ì¥ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5de47a",
   "metadata": {
    "id": "ef5de47a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'id': [1,2], 'ì´ë¦„': ['í™ê¸¸ë™','ì„êº½ì •']})\n",
    "df.set_head_att({'id': 'ë²ˆí˜¸', 'ì´ë¦„': 'ì„±ëª…'})\n",
    "print('ì»¬ëŸ¼ ì„¤ëª…:', df.get_head_att())\n",
    "df.head_att()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39445237",
   "metadata": {
    "id": "39445237"
   },
   "source": [
    "## 4. ì»¤ë°‹/ë³µì› ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0dfd95",
   "metadata": {
    "id": "9b0dfd95"
   },
   "outputs": [],
   "source": [
    "# DataFrame ì»¤ë°‹ ë° ë³µì› í…ŒìŠ¤íŠ¸\n",
    "df2 = pd.DataFrame({'id': [3,4], 'ì´ë¦„': ['ì´ëª½ë£¡','ì„±ì¶˜í–¥']})\n",
    "helper.pd_commit(df2, 'í…ŒìŠ¤íŠ¸ì»¤ë°‹')\n",
    "ë³µì› = helper.pd_checkout('í…ŒìŠ¤íŠ¸ì»¤ë°‹')\n",
    "print('ë³µì›ëœ DataFrame:')\n",
    "print(ë³µì›)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e7ea02",
   "metadata": {
    "id": "42e7ea02"
   },
   "source": [
    "## 5. ì—ëŸ¬ ë° ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5791f",
   "metadata": {
    "id": "c5f5791f"
   },
   "outputs": [],
   "source": [
    "# ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¤ë°‹ ë³µì› ì‹œë„\n",
    "df_empty = helper.pd_checkout('ì—†ëŠ”ì»¤ë°‹')\n",
    "print('ì—†ëŠ” ì»¤ë°‹ ë³µì› ê²°ê³¼:', df_empty.empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HsAjDSHPKIwZ",
   "metadata": {
    "id": "HsAjDSHPKIwZ"
   },
   "outputs": [],
   "source": [
    "helper.pd_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edac51",
   "metadata": {
    "id": "42edac51"
   },
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ í—¬í¼ í•¨ìˆ˜ ë° ë³€ìˆ˜ ì •ì˜\n",
    "test_results = []\n",
    "\n",
    "# í™˜ê²½ë³„ í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "if helper.is_colab:\n",
    "    test_csv_file = \"/content/drive/MyDrive/homepage/jupyter_hangul/data/test_sample.csv\"\n",
    "    test_csv_create_file = \"/content/drive/MyDrive/homepage/jupyter_hangul/test_sample_created.csv\"\n",
    "else:\n",
    "    test_csv_file = \"data/test_sample.csv\"\n",
    "    test_csv_create_file = \"test_sample_created.csv\"\n",
    "\n",
    "def run_test(test_name, test_func):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í—¬í¼ í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        result = test_func()\n",
    "        if result is True or result is not None:\n",
    "            print(f\"âœ… {test_name}: ì„±ê³µ\")\n",
    "            test_results.append({\"test\": test_name, \"status\": \"ì„±ê³µ\", \"error\": None})\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"âŒ {test_name}: ì‹¤íŒ¨ - ê²°ê³¼ê°€ None ë˜ëŠ” False\")\n",
    "            test_results.append({\"test\": test_name, \"status\": \"ì‹¤íŒ¨\", \"error\": \"ê²°ê³¼ê°€ None ë˜ëŠ” False\"})\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {test_name}: ì‹¤íŒ¨ - {str(e)}\")\n",
    "        test_results.append({\"test\": test_name, \"status\": \"ì‹¤íŒ¨\", \"error\": str(e)})\n",
    "        return None\n",
    "\n",
    "def expect_error(test_name, test_func, expected_error=Exception):\n",
    "    \"\"\"ì—ëŸ¬ ë°œìƒì„ ì˜ˆìƒí•˜ëŠ” í…ŒìŠ¤íŠ¸ í—¬í¼ í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        test_func()\n",
    "        print(f\"âŒ {test_name}: ì‹¤íŒ¨ - ì˜ˆìƒëœ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ\")\n",
    "        test_results.append({\"test\": test_name, \"status\": \"ì‹¤íŒ¨\", \"error\": \"ì˜ˆìƒëœ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ\"})\n",
    "        return False\n",
    "    except expected_error as e:\n",
    "        print(f\"âœ… {test_name}: ì„±ê³µ - ì˜ˆìƒëœ ì—ëŸ¬ ë°œìƒ: {type(e).__name__}\")\n",
    "        test_results.append({\"test\": test_name, \"status\": \"ì„±ê³µ\", \"error\": None})\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {test_name}: ì‹¤íŒ¨ - ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì—ëŸ¬: {type(e).__name__}\")\n",
    "        test_results.append({\"test\": test_name, \"status\": \"ì‹¤íŒ¨\", \"error\": f\"ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì—ëŸ¬: {type(e).__name__}\"})\n",
    "        return False\n",
    "\n",
    "# ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±\n",
    "if not os.path.exists(test_csv_file):\n",
    "    print(f\"âš ï¸ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤: {test_csv_file}\")\n",
    "    # ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "    os.makedirs(os.path.dirname(test_csv_file), exist_ok=True)\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ìš© CSV íŒŒì¼ ìƒì„±\n",
    "    csv_content = \"\"\"id,name,age,score\n",
    "1,í™ê¸¸ë™,25,85.5\n",
    "2,ì´ëª½ë£¡,22,92.3\n",
    "3,ì„±ì¶˜í–¥,20,78.1\n",
    "4,ì„êº½ì •,28,88.7\n",
    "5,ë°•ë¬¸ìˆ˜,26,90.2\"\"\"\n",
    "\n",
    "    with open(test_csv_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(csv_content)\n",
    "    print(f\"ğŸ“„ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ: {test_csv_file}\")\n",
    "else:\n",
    "    print(f\"ğŸ“„ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‚¬ìš©: {test_csv_file}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ìƒì„±í•  íŒŒì¼ë„ ë§Œë“¤ì–´ ë‘¡ë‹ˆë‹¤\n",
    "csv_content_for_creation = \"\"\"id,name,age,score\n",
    "1,í™ê¸¸ë™,25,85.5\n",
    "2,ì´ëª½ë£¡,22,92.3\n",
    "3,ì„±ì¶˜í–¥,20,78.1\n",
    "4,ì„êº½ì •,28,88.7\n",
    "5,ë°•ë¬¸ìˆ˜,26,90.2\"\"\"\n",
    "\n",
    "with open(test_csv_create_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(csv_content_for_creation)\n",
    "\n",
    "print(f\"ğŸ”§ í…ŒìŠ¤íŠ¸ í—¬í¼ í•¨ìˆ˜ ë° í…ŒìŠ¤íŠ¸ íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"ğŸ“ í˜„ì¬ í™˜ê²½: {'Colab' if helper.is_colab else 'ë¡œì»¬'}\")\n",
    "print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ: {test_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b911381e",
   "metadata": {
    "id": "b911381e"
   },
   "outputs": [],
   "source": [
    "# íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (run_test í•¨ìˆ˜ ì •ì˜ í›„)\n",
    "print(\"ğŸ“‚ íŒŒì¼ ì½ê¸° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "run_test(\"ë¡œì»¬ íŒŒì¼ ì½ê¸°\", test_pd_read_csv_local_file)\n",
    "run_test(\"ì˜µì…˜ í¬í•¨ íŒŒì¼ ì½ê¸°\", test_pd_read_csv_with_options)\n",
    "run_test(\"StringIO ì½ê¸°\", test_pd_read_csv_stringio)\n",
    "run_test(\"URL ê°ì§€ ë¡œì§\", test_pd_read_csv_url_detection)\n",
    "run_test(\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼\", test_pd_read_csv_file_not_found)\n",
    "run_test(\"í™˜ê²½ë³„ ê²½ë¡œ ì²˜ë¦¬\", test_pd_read_csv_environment_path)\n",
    "run_test(\"ìƒì„±ëœ í…ŒìŠ¤íŠ¸ íŒŒì¼\", test_pd_read_csv_created_file)\n",
    "print(\"ğŸ“‚ íŒŒì¼ ì½ê¸° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad6162",
   "metadata": {
    "id": "cbad6162"
   },
   "source": [
    "## 6. pandas í™•ì¥ ê¸°ëŠ¥ ìƒì„¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e64b8",
   "metadata": {
    "id": "666e64b8"
   },
   "outputs": [],
   "source": [
    "# pandas í™•ì¥ ê¸°ëŠ¥ ì„¤ì •\n",
    "def test_pandas_extension_setup():\n",
    "    \"\"\"pandas í™•ì¥ ê¸°ëŠ¥ ì„¤ì • í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ”§ pandas í™•ì¥ ê¸°ëŠ¥ ì„¤ì •\")\n",
    "\n",
    "    helper.set_pandas_extension()\n",
    "\n",
    "    # DataFrameì— ìƒˆ ë©”ì„œë“œê°€ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "    test_df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n",
    "\n",
    "    required_methods = [\n",
    "        'set_head_att', 'get_head_att', 'head_att', 'remove_head_att', 'clear_head_att',\n",
    "        'set_head_ext', 'set_head_column', 'get_head_ext', 'list_head_ext', 'remove_head_ext', 'clear_head_ext'\n",
    "    ]\n",
    "\n",
    "    for method in required_methods:\n",
    "        if hasattr(test_df, method):\n",
    "            print(f\"âœ… {method} ë©”ì„œë“œ ì¶”ê°€ë¨\")\n",
    "        else:\n",
    "            raise Exception(f\"âŒ {method} ë©”ì„œë“œê°€ ì¶”ê°€ë˜ì§€ ì•ŠìŒ\")\n",
    "\n",
    "    return True\n",
    "\n",
    "run_test(\"pandas í™•ì¥ ê¸°ëŠ¥ ì„¤ì •\", test_pandas_extension_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadee577",
   "metadata": {
    "id": "eadee577"
   },
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ìš© DataFrame ìƒì„±\n",
    "test_df = pd.DataFrame({\n",
    "    'student_id': [1001, 1002, 1003],\n",
    "    'name': ['ê¹€ì² ìˆ˜', 'ì´ì˜í¬', 'ë°•ë¯¼ìˆ˜'],\n",
    "    'age': [20, 21, 22],\n",
    "    'score': [85.5, 92.3, 78.1],\n",
    "    'grade': ['B+', 'A', 'C+']\n",
    "})\n",
    "\n",
    "print(\"ğŸ“Š í…ŒìŠ¤íŠ¸ìš© DataFrame ìƒì„±\")\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921e5be",
   "metadata": {
    "id": "e921e5be"
   },
   "outputs": [],
   "source": [
    "def test_set_head_att_dict():\n",
    "    \"\"\"ë”•ì…”ë„ˆë¦¬ë¡œ ì»¬ëŸ¼ ì„¤ëª… ì„¤ì • í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ“ ë”•ì…”ë„ˆë¦¬ë¡œ ì»¬ëŸ¼ ì„¤ëª… ì„¤ì •\")\n",
    "\n",
    "    descriptions = {\n",
    "        'student_id': 'í•™ìƒ ID',\n",
    "        'name': 'í•™ìƒ ì´ë¦„',\n",
    "        'age': 'ë‚˜ì´',\n",
    "        'score': 'ì ìˆ˜',\n",
    "        'grade': 'ë“±ê¸‰'\n",
    "    }\n",
    "\n",
    "    test_df.set_head_att(descriptions)\n",
    "\n",
    "    # ì„¤ì •ëœ ì„¤ëª… í™•ì¸\n",
    "    stored_descriptions = test_df.get_head_att()\n",
    "    print(f\"ğŸ’¾ ì €ì¥ëœ ì„¤ëª…: {stored_descriptions}\")\n",
    "\n",
    "    for key, value in descriptions.items():\n",
    "        assert stored_descriptions[key] == value, f\"ì„¤ëª…ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ: {key}\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_set_head_att_individual():\n",
    "    \"\"\"ê°œë³„ ì»¬ëŸ¼ ì„¤ëª… ì„¤ì • í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ“ ê°œë³„ ì»¬ëŸ¼ ì„¤ëª… ì„¤ì •\")\n",
    "\n",
    "    test_df.set_head_att('score', 'ì¤‘ê°„ê³ ì‚¬ ì ìˆ˜')\n",
    "\n",
    "    score_desc = test_df.get_head_att('score')\n",
    "    print(f\"ğŸ“Š score ì„¤ëª…: {score_desc}\")\n",
    "\n",
    "    assert score_desc == 'ì¤‘ê°„ê³ ì‚¬ ì ìˆ˜', \"ê°œë³„ ì„¤ëª… ì„¤ì • ì‹¤íŒ¨\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_get_head_att():\n",
    "    \"\"\"ì»¬ëŸ¼ ì„¤ëª… ì¡°íšŒ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ” ì»¬ëŸ¼ ì„¤ëª… ì¡°íšŒ\")\n",
    "\n",
    "    # ì „ì²´ ì„¤ëª… ì¡°íšŒ\n",
    "    all_descriptions = test_df.get_head_att()\n",
    "    print(f\"ğŸ“‹ ì „ì²´ ì„¤ëª…: {len(all_descriptions)}ê°œ\")\n",
    "\n",
    "    # ê°œë³„ ì„¤ëª… ì¡°íšŒ\n",
    "    name_desc = test_df.get_head_att('name')\n",
    "    print(f\"ğŸ‘¤ name ì„¤ëª…: {name_desc}\")\n",
    "\n",
    "    assert isinstance(all_descriptions, dict), \"ì „ì²´ ì„¤ëª…ì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜\"\n",
    "    assert name_desc == 'í•™ìƒ ì´ë¦„', \"ê°œë³„ ì„¤ëª… ì¡°íšŒ ì‹¤íŒ¨\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_head_att_output():\n",
    "    \"\"\"head_att ì¶œë ¥ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ–¨ï¸ head_att ì¶œë ¥ ê¸°ëŠ¥\")\n",
    "\n",
    "    # print í˜•ì‹ ì¶œë ¥\n",
    "    print(\"\\nğŸ“„ Print í˜•ì‹:\")\n",
    "    test_df.head_att(3)\n",
    "\n",
    "    # string í˜•ì‹ ì¶œë ¥\n",
    "    print(\"\\nğŸ“ String í˜•ì‹:\")\n",
    "    str_output = test_df.head_att(2, out='str')\n",
    "    print(\"String ì¶œë ¥ ê²°ê³¼:\")\n",
    "    print(str_output)\n",
    "\n",
    "    assert isinstance(str_output, str), \"ë¬¸ìì—´ ì¶œë ¥ì´ ë¬¸ìì—´ì´ ì•„ë‹˜\"\n",
    "    assert 'í•™ìƒ ì´ë¦„' in str_output, \"í•œê¸€ ì„¤ëª…ì´ ì¶œë ¥ì— ì—†ìŒ\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_remove_head_att():\n",
    "    \"\"\"ì»¬ëŸ¼ ì„¤ëª… ì‚­ì œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ—‘ï¸ ì»¬ëŸ¼ ì„¤ëª… ì‚­ì œ\")\n",
    "\n",
    "    # ë°±ì—…ìš© DataFrame ìƒì„±\n",
    "    df_copy = test_df.copy()\n",
    "    df_copy.set_head_att({'test': 'í…ŒìŠ¤íŠ¸'})\n",
    "\n",
    "    # ê°œë³„ ì‚­ì œ\n",
    "    df_copy.remove_head_att('test')\n",
    "\n",
    "    descriptions = df_copy.get_head_att()\n",
    "    assert 'test' not in descriptions, \"ì‚­ì œëœ ì„¤ëª…ì´ ì—¬ì „íˆ ì¡´ì¬í•¨\"\n",
    "\n",
    "    # ë¦¬ìŠ¤íŠ¸ë¡œ ì‚­ì œ\n",
    "    df_copy.remove_head_att(['name', 'age'])\n",
    "\n",
    "    descriptions = df_copy.get_head_att()\n",
    "    assert 'name' not in descriptions, \"name ì„¤ëª…ì´ ì‚­ì œë˜ì§€ ì•ŠìŒ\"\n",
    "    assert 'age' not in descriptions, \"age ì„¤ëª…ì´ ì‚­ì œë˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "    return True\n",
    "\n",
    "# ê¸°ë³¸ ì»¬ëŸ¼ ì„¤ëª… ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "run_test(\"ë”•ì…”ë„ˆë¦¬ ì„¤ëª… ì„¤ì •\", test_set_head_att_dict)\n",
    "run_test(\"ê°œë³„ ì„¤ëª… ì„¤ì •\", test_set_head_att_individual)\n",
    "run_test(\"ì„¤ëª… ì¡°íšŒ\", test_get_head_att)\n",
    "run_test(\"head_att ì¶œë ¥\", test_head_att_output)\n",
    "run_test(\"ì„¤ëª… ì‚­ì œ\", test_remove_head_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe067d5e",
   "metadata": {
    "id": "fe067d5e"
   },
   "source": [
    "## 7. ì»¬ëŸ¼ ì„¸íŠ¸ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d700f0",
   "metadata": {
    "id": "d8d700f0"
   },
   "outputs": [],
   "source": [
    "def test_set_head_ext_bulk():\n",
    "    \"\"\"ì „ì²´ ì»¬ëŸ¼ ì„¸íŠ¸ ì„¤ì • í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ”§ ì „ì²´ ì»¬ëŸ¼ ì„¸íŠ¸ ì„¤ì •\")\n",
    "\n",
    "    korean_columns = {\n",
    "        'student_id': 'ID',\n",
    "        'name': 'ì´ë¦„',\n",
    "        'age': 'ë‚˜ì´',\n",
    "        'score': 'ì ìˆ˜',\n",
    "        'grade': 'ë“±ê¸‰'\n",
    "    }\n",
    "\n",
    "    test_df.set_head_ext('kr', korean_columns)\n",
    "\n",
    "    # ì„¤ì • í™•ì¸\n",
    "    kr_set = test_df.get_head_ext('kr')\n",
    "    print(f\"ğŸ‡°ğŸ‡· í•œê¸€ ì„¸íŠ¸: {kr_set}\")\n",
    "\n",
    "    assert 'kr' in test_df.get_head_ext(), \"í•œê¸€ ì„¸íŠ¸ê°€ ì¶”ê°€ë˜ì§€ ì•ŠìŒ\"\n",
    "    assert kr_set['columns']['name'] == 'ì´ë¦„', \"í•œê¸€ ë§¤í•‘ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_set_head_ext_individual():\n",
    "    \"\"\"ê°œë³„ ì»¬ëŸ¼ ì„¸íŠ¸ ì„¤ì • í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ”§ ê°œë³„ ì»¬ëŸ¼ ì„¸íŠ¸ ì„¤ì •\")\n",
    "\n",
    "    # ìƒˆ ì„¸íŠ¸ì— ê°œë³„ ì»¬ëŸ¼ ì¶”ê°€\n",
    "    test_df.set_head_ext('desc', 'student_id', 'í•™ìƒ ì‹ë³„ ë²ˆí˜¸')\n",
    "    test_df.set_head_ext('desc', 'name', 'í•™ìƒ ì„±ëª…')\n",
    "\n",
    "    desc_set = test_df.get_head_ext('desc')\n",
    "    print(f\"ğŸ“ ì„¤ëª… ì„¸íŠ¸: {desc_set}\")\n",
    "\n",
    "    assert desc_set['columns']['student_id'] == 'í•™ìƒ ì‹ë³„ ë²ˆí˜¸', \"ê°œë³„ ì„¤ì • ì‹¤íŒ¨\"\n",
    "    assert desc_set['columns']['name'] == 'í•™ìƒ ì„±ëª…', \"ê°œë³„ ì„¤ì • ì‹¤íŒ¨\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_set_head_column():\n",
    "    \"\"\"ì»¬ëŸ¼ëª… ë³€ê²½ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ”„ ì»¬ëŸ¼ëª… ë³€ê²½\")\n",
    "\n",
    "    # ì›ë³¸ ì»¬ëŸ¼ëª… ì €ì¥\n",
    "    original_columns = list(test_df.columns)\n",
    "    print(f\"ğŸ“‹ ì›ë³¸ ì»¬ëŸ¼: {original_columns}\")\n",
    "\n",
    "    # í•œê¸€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½\n",
    "    test_df.set_head_column('kr')\n",
    "    kr_columns = list(test_df.columns)\n",
    "    print(f\"ğŸ‡°ğŸ‡· í•œê¸€ ì»¬ëŸ¼: {kr_columns}\")\n",
    "\n",
    "    assert 'ID' in kr_columns, \"í•œê¸€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½ë˜ì§€ ì•ŠìŒ\"\n",
    "    assert 'ì´ë¦„' in kr_columns, \"í•œê¸€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½ë˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "    # ì›ë³¸ìœ¼ë¡œ ë³µì›\n",
    "    test_df.set_head_column('org')\n",
    "    restored_columns = list(test_df.columns)\n",
    "    print(f\"ğŸ”™ ë³µì›ëœ ì»¬ëŸ¼: {restored_columns}\")\n",
    "\n",
    "    assert restored_columns == original_columns, \"ì›ë³¸ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³µì›ë˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_list_head_ext():\n",
    "    \"\"\"ì»¬ëŸ¼ ì„¸íŠ¸ ëª©ë¡ ì¡°íšŒ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ“‹ ì»¬ëŸ¼ ì„¸íŠ¸ ëª©ë¡ ì¡°íšŒ\")\n",
    "\n",
    "    test_df.list_head_ext()\n",
    "\n",
    "    all_sets = test_df.get_head_ext()\n",
    "    print(f\"ğŸ—‚ï¸ ì „ì²´ ì„¸íŠ¸: {list(all_sets.keys())}\")\n",
    "\n",
    "    expected_sets = ['org', 'kr', 'desc']\n",
    "    for set_name in expected_sets:\n",
    "        assert set_name in all_sets, f\"{set_name} ì„¸íŠ¸ê°€ ì—†ìŒ\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_remove_head_ext():\n",
    "    \"\"\"ì»¬ëŸ¼ ì„¸íŠ¸ ì‚­ì œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ—‘ï¸ ì»¬ëŸ¼ ì„¸íŠ¸ ì‚­ì œ\")\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ìš© ì„¸íŠ¸ ì¶”ê°€\n",
    "    test_df.set_head_ext('temp', {'name': 'ì„ì‹œ'})\n",
    "\n",
    "    # ì‚­ì œ\n",
    "    test_df.remove_head_ext('temp')\n",
    "\n",
    "    all_sets = test_df.get_head_ext()\n",
    "    assert 'temp' not in all_sets, \"ì„¸íŠ¸ê°€ ì‚­ì œë˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "    return True\n",
    "\n",
    "# ì»¬ëŸ¼ ì„¸íŠ¸ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "run_test(\"ì „ì²´ ì„¸íŠ¸ ì„¤ì •\", test_set_head_ext_bulk)\n",
    "run_test(\"ê°œë³„ ì„¸íŠ¸ ì„¤ì •\", test_set_head_ext_individual)\n",
    "run_test(\"ì»¬ëŸ¼ëª… ë³€ê²½\", test_set_head_column)\n",
    "run_test(\"ì„¸íŠ¸ ëª©ë¡ ì¡°íšŒ\", test_list_head_ext)\n",
    "run_test(\"ì„¸íŠ¸ ì‚­ì œ\", test_remove_head_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631aa35",
   "metadata": {
    "id": "7631aa35"
   },
   "source": [
    "## 8. ê³ ê¸‰ ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788a264",
   "metadata": {
    "id": "9788a264"
   },
   "outputs": [],
   "source": [
    "def test_error_get_head_att_nonexistent():\n",
    "    \"\"\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì„¤ëª… ì¡°íšŒ ë™ì‘ í…ŒìŠ¤íŠ¸ - ì»¬ëŸ¼ëª… ë°˜í™˜\"\"\"\n",
    "    result = test_df.get_head_att('nonexistent_column')\n",
    "    # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ì— ëŒ€í•´ì„œëŠ” ì»¬ëŸ¼ëª… ìì²´ë¥¼ ë°˜í™˜\n",
    "    assert result == 'nonexistent_column', f\"ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê²°ê³¼: {result}\"\n",
    "    return True\n",
    "\n",
    "def test_error_get_head_att_wrong_type():\n",
    "    \"\"\"ì˜ëª»ëœ íƒ€ì…ì˜ í‚¤ë¡œ ì¡°íšŒ ì—ëŸ¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    test_df.get_head_att(123)\n",
    "\n",
    "def test_error_set_head_att_wrong_usage():\n",
    "    \"\"\"ì˜ëª»ëœ ì‚¬ìš©ë²• ì—ëŸ¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    test_df.set_head_att(\"key_only\")\n",
    "\n",
    "def test_error_set_head_ext_wrong_type():\n",
    "    \"\"\"ì˜ëª»ëœ íƒ€ì…ìœ¼ë¡œ ì„¸íŠ¸ ì„¤ì • ì—ëŸ¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    test_df.set_head_ext(123, {'test': 'í…ŒìŠ¤íŠ¸'})\n",
    "\n",
    "def test_error_set_head_ext_empty_dict():\n",
    "    \"\"\"ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì„¸íŠ¸ ì„¤ì • ì—ëŸ¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    test_df.set_head_ext('empty', {})\n",
    "\n",
    "def test_error_set_head_ext_nonexistent_column():\n",
    "    \"\"\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ìœ¼ë¡œ ì„¸íŠ¸ ì„¤ì • ì—ëŸ¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    test_df.set_head_ext('test', {'nonexistent': 'ì¡´ì¬í•˜ì§€ì•ŠìŒ'})\n",
    "\n",
    "def test_error_set_head_ext_org_name():\n",
    "    \"\"\"ì˜ˆì•½ëœ 'org' ì„¸íŠ¸ëª… ì‚¬ìš© ì—ëŸ¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    test_df.set_head_ext('org', {'name': 'ì´ë¦„'})\n",
    "\n",
    "def test_error_set_head_column_nonexistent():\n",
    "    \"\"\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì„¸íŠ¸ë¡œ ì»¬ëŸ¼ ë³€ê²½ ì—ëŸ¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    test_df.set_head_column('nonexistent_set')\n",
    "\n",
    "def test_error_head_att_wrong_out_option():\n",
    "    \"\"\"ì˜ëª»ëœ out ì˜µì…˜ ì—ëŸ¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    test_df.head_att(out='wrong_option')\n",
    "\n",
    "# ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "run_test(\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì„¤ëª… ì¡°íšŒ\", test_error_get_head_att_nonexistent)  # ì¼ë°˜ í…ŒìŠ¤íŠ¸ë¡œ ë³€ê²½\n",
    "expect_error(\"ì˜ëª»ëœ íƒ€ì… í‚¤ ì¡°íšŒ\", test_error_get_head_att_wrong_type, TypeError)\n",
    "expect_error(\"ì˜ëª»ëœ ì‚¬ìš©ë²•\", test_error_set_head_att_wrong_usage, ValueError)\n",
    "expect_error(\"ì˜ëª»ëœ íƒ€ì… ì„¸íŠ¸ëª…\", test_error_set_head_ext_wrong_type, TypeError)\n",
    "expect_error(\"ë¹ˆ ë”•ì…”ë„ˆë¦¬ ì„¸íŠ¸\", test_error_set_head_ext_empty_dict, ValueError)\n",
    "expect_error(\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ ì„¸íŠ¸\", test_error_set_head_ext_nonexistent_column, KeyError)\n",
    "expect_error(\"ì˜ˆì•½ëœ org ì„¸íŠ¸ëª…\", test_error_set_head_ext_org_name, ValueError)\n",
    "expect_error(\"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì„¸íŠ¸ë¡œ ë³€ê²½\", test_error_set_head_column_nonexistent, KeyError)\n",
    "expect_error(\"ì˜ëª»ëœ out ì˜µì…˜\", test_error_head_att_wrong_out_option, ValueError)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f774e0a",
   "metadata": {
    "id": "5f774e0a"
   },
   "source": [
    "## 9. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27bbbd",
   "metadata": {
    "id": "6e27bbbd"
   },
   "outputs": [],
   "source": [
    "def test_dir_start():\n",
    "    \"\"\"dir_start í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ” dir_start í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    # DataFrameì˜ 'head'ë¡œ ì‹œì‘í•˜ëŠ” ë©”ì„œë“œ ì°¾ê¸°\n",
    "    print(\"DataFrameì˜ 'head'ë¡œ ì‹œì‘í•˜ëŠ” ë©”ì„œë“œ:\")\n",
    "    helper.dir_start(pd.DataFrame, 'head')\n",
    "\n",
    "    # ì‹¤ì œë¡œ head ê´€ë ¨ ë©”ì„œë“œë“¤ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "    df_methods = [attr for attr in dir(pd.DataFrame) if attr.startswith('head')]\n",
    "    assert len(df_methods) > 0, \"headë¡œ ì‹œì‘í•˜ëŠ” ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "    assert 'head' in df_methods, \"head ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "\n",
    "    return True\n",
    "\n",
    "def test_series_head_att():\n",
    "    \"\"\"Series head_att ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ“Š Series head_att í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    # Series ìƒì„±\n",
    "    test_series = pd.Series([1, 2, 3, 4, 5], name='scores')\n",
    "\n",
    "    # Seriesì— ì„¤ëª… ì¶”ê°€\n",
    "    test_series.set_head_att('scores', 'ì‹œí—˜ ì ìˆ˜')\n",
    "\n",
    "    # ì¶œë ¥ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\nğŸ“ Series head_att ì¶œë ¥:\")\n",
    "    test_series.head_att(3)\n",
    "\n",
    "    # ë¬¸ìì—´ ì¶œë ¥ í…ŒìŠ¤íŠ¸\n",
    "    str_output = test_series.head_att(2, out='str')\n",
    "    assert isinstance(str_output, str), \"Series ë¬¸ìì—´ ì¶œë ¥ì´ ë¬¸ìì—´ì´ ì•„ë‹˜\"\n",
    "    assert 'ì‹œí—˜ ì ìˆ˜' in str_output, \"Series í•œê¸€ ì„¤ëª…ì´ ì¶œë ¥ì— ì—†ìŒ\"\n",
    "\n",
    "    return True\n",
    "\n",
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\n",
    "run_test(\"dir_start í•¨ìˆ˜\", test_dir_start)\n",
    "run_test(\"Series head_att\", test_series_head_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f947e",
   "metadata": {
    "id": "875f947e"
   },
   "source": [
    "## 10. ì •ë¦¬ ë° cleanup í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6fe6d",
   "metadata": {
    "id": "b0e6fe6d"
   },
   "outputs": [],
   "source": [
    "def test_clear_functions():\n",
    "    \"\"\"ì´ˆê¸°í™” í•¨ìˆ˜ë“¤ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    print(\"ğŸ§¹ ì´ˆê¸°í™” í•¨ìˆ˜ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "    # ì»¬ëŸ¼ ì„¤ëª… ì´ˆê¸°í™”\n",
    "    test_df.clear_head_att()\n",
    "    descriptions = test_df.get_head_att()\n",
    "    assert len(descriptions) == 0, \"ì»¬ëŸ¼ ì„¤ëª…ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ\"\n",
    "    print(\"âœ… ì»¬ëŸ¼ ì„¤ëª… ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "\n",
    "    # ì»¬ëŸ¼ ì„¸íŠ¸ ì´ˆê¸°í™”\n",
    "    test_df.clear_head_ext()\n",
    "    all_sets = test_df.get_head_ext()\n",
    "    assert list(all_sets.keys()) == ['org'], \"ì»¬ëŸ¼ ì„¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ\"\n",
    "    print(\"âœ… ì»¬ëŸ¼ ì„¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ\")\n",
    "\n",
    "    return True\n",
    "\n",
    "def cleanup_test_files():\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬\"\"\"\n",
    "    print(\"ğŸ—‘ï¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬\")\n",
    "\n",
    "    files_to_remove = [test_csv_create_file]\n",
    "\n",
    "    # ìƒì„±í•œ í…ŒìŠ¤íŠ¸ íŒŒì¼ë§Œ ì‚­ì œ (ê¸°ì¡´ data/test_sample.csvëŠ” ë³´ì¡´)\n",
    "    for file_path in files_to_remove:\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "            print(f\"âœ… {file_path} ì‚­ì œ ì™„ë£Œ\")\n",
    "\n",
    "    return True\n",
    "\n",
    "run_test(\"ì´ˆê¸°í™” í•¨ìˆ˜\", test_clear_functions)\n",
    "run_test(\"íŒŒì¼ ì •ë¦¬\", cleanup_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0e57f",
   "metadata": {
    "id": "65d0e57f"
   },
   "outputs": [],
   "source": [
    "# ì¤‘ê°„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸\n",
    "print(\"ğŸ”„ ì¤‘ê°„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸\")\n",
    "print(f\"í˜„ì¬ê¹Œì§€ ì´ í…ŒìŠ¤íŠ¸: {len(test_results)}ê°œ\")\n",
    "\n",
    "# ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ê°œìˆ˜ ê³„ì‚° (ìƒíƒœê°’ í†µì¼)\n",
    "failed_tests = len([result for result in test_results if result['status'] in ['ì‹¤íŒ¨', 'FAIL']])\n",
    "passed_tests = len(test_results) - failed_tests\n",
    "\n",
    "print(f\"âœ… ì„±ê³µ: {passed_tests}ê°œ\")\n",
    "print(f\"âŒ ì‹¤íŒ¨: {failed_tests}ê°œ\")\n",
    "\n",
    "if failed_tests > 0:\n",
    "    print(\"\\nì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:\")\n",
    "    for result in test_results:\n",
    "        if result['status'] in ['ì‹¤íŒ¨', 'FAIL']:\n",
    "            print(f\"- {result['test']}: {result['error']}\")\n",
    "\n",
    "print(\"\\nâ³ ê³„ì†í•´ì„œ ë‚˜ë¨¸ì§€ í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘...\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e4fe2",
   "metadata": {
    "id": "c39e4fe2"
   },
   "source": [
    "## 11. í†µí•© ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d290f42",
   "metadata": {
    "id": "7d290f42"
   },
   "outputs": [],
   "source": [
    "# ğŸ’¾ ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "\n",
    "# ìºì‹œ í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™” (ì¤‘ë³µ ë°©ì§€)\n",
    "cache_tests = []\n",
    "\n",
    "# 9.1 ìºì‹œ í‚¤ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "def test_cache_key_generation():\n",
    "    \"\"\"ìºì‹œ í‚¤ ìƒì„± ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        # ê¸°ë³¸ í‚¤ ìƒì„±\n",
    "        key1 = helper.cache_key(\"test_model\", [1, 2, 3], param1=\"value1\")\n",
    "        key2 = helper.cache_key(\"test_model\", [1, 2, 3], param1=\"value1\")\n",
    "        key3 = helper.cache_key(\"test_model\", [1, 2, 4], param1=\"value1\")\n",
    "\n",
    "        # ë™ì¼í•œ ì…ë ¥ì€ ë™ì¼í•œ í‚¤\n",
    "        assert key1 == key2, \"ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•´ ë‹¤ë¥¸ í‚¤ê°€ ìƒì„±ë¨\"\n",
    "\n",
    "        # ë‹¤ë¥¸ ì…ë ¥ì€ ë‹¤ë¥¸ í‚¤\n",
    "        assert key1 != key3, \"ë‹¤ë¥¸ ì…ë ¥ì— ëŒ€í•´ ë™ì¼í•œ í‚¤ê°€ ìƒì„±ë¨\"\n",
    "\n",
    "        # í‚¤ê°€ ë¬¸ìì—´ì¸ì§€ í™•ì¸\n",
    "        assert isinstance(key1, str), \"í‚¤ê°€ ë¬¸ìì—´ì´ ì•„ë‹˜\"\n",
    "        assert len(key1) > 0, \"ë¹ˆ í‚¤ê°€ ìƒì„±ë¨\"\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# 9.2 ê¸°ë³¸ ì €ì¥/ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
    "def test_basic_save_load():\n",
    "    \"\"\"ê¸°ë³¸ ì €ì¥/ë¡œë“œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        # ìºì‹œ ì •ë¦¬\n",
    "        helper.cache_clear()\n",
    "\n",
    "        # í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "        test_data = {\"model\": \"test\", \"accuracy\": 0.95, \"params\": [1, 2, 3]}\n",
    "        test_key = helper.cache_key(\"test_save_load\")\n",
    "\n",
    "        # ì €ì¥\n",
    "        save_result = helper.cache_save(test_key, test_data)\n",
    "        assert save_result, \"ì €ì¥ ì‹¤íŒ¨\"\n",
    "\n",
    "        # ì¡´ì¬ í™•ì¸\n",
    "        exists = helper.cache_exists(test_key)\n",
    "        assert exists, \"ì €ì¥ëœ í‚¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "        # ë¡œë“œ\n",
    "        loaded_data = helper.cache_load(test_key)\n",
    "        assert loaded_data is not None, \"ë¡œë“œ ì‹¤íŒ¨\"\n",
    "        assert loaded_data == test_data, \"ë¡œë“œëœ ë°ì´í„°ê°€ ë‹¤ë¦„\"\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"ê¸°ë³¸ ì €ì¥/ë¡œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# 9.3 DataFrame ìºì‹œ í…ŒìŠ¤íŠ¸\n",
    "def test_dataframe_cache():\n",
    "    \"\"\"DataFrame ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        # í…ŒìŠ¤íŠ¸ DataFrame\n",
    "        test_df_cache = pd.DataFrame({\n",
    "            'id': [1, 2, 3],\n",
    "            'name': ['A', 'B', 'C'],\n",
    "            'score': [85.5, 92.3, 78.1]\n",
    "        })\n",
    "\n",
    "        df_key = helper.cache_key(\"test_dataframe\", test_df_cache.shape)\n",
    "\n",
    "        # DataFrame ì €ì¥\n",
    "        save_result = helper.cache_save(df_key, test_df_cache)\n",
    "        assert save_result, \"DataFrame ì €ì¥ ì‹¤íŒ¨\"\n",
    "\n",
    "        # DataFrame ë¡œë“œ\n",
    "        loaded_df = helper.cache_load(df_key)\n",
    "        assert loaded_df is not None, \"DataFrame ë¡œë“œ ì‹¤íŒ¨\"\n",
    "        assert isinstance(loaded_df, pd.DataFrame), \"ë¡œë“œëœ ê°ì²´ê°€ DataFrameì´ ì•„ë‹˜\"\n",
    "        assert loaded_df.shape == test_df_cache.shape, \"DataFrame í˜•íƒœê°€ ë‹¤ë¦„\"\n",
    "        assert loaded_df.equals(test_df_cache), \"DataFrame ë‚´ìš©ì´ ë‹¤ë¦„\"\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"DataFrame ìºì‹œ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# run_test í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìºì‹œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "run_test(\"ìºì‹œ í‚¤ ìƒì„±\", test_cache_key_generation)\n",
    "run_test(\"ê¸°ë³¸ ì €ì¥/ë¡œë“œ\", test_basic_save_load)\n",
    "run_test(\"DataFrame ìºì‹œ\", test_dataframe_cache)\n",
    "\n",
    "print(f\"ğŸ’¾ ìºì‹œ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba8e34",
   "metadata": {
    "id": "c6ba8e34"
   },
   "outputs": [],
   "source": [
    "# 9.4 numpy ë°°ì—´ ìºì‹œ í…ŒìŠ¤íŠ¸\n",
    "def test_numpy_cache():\n",
    "    \"\"\"numpy ë°°ì—´ ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        # í…ŒìŠ¤íŠ¸ ë°°ì—´\n",
    "        test_array = np.random.rand(5, 3)\n",
    "        array_key = helper.cache_key(\"test_array\", test_array.shape)\n",
    "\n",
    "        # ë°°ì—´ ì €ì¥\n",
    "        save_result = helper.cache_save(array_key, test_array)\n",
    "        assert save_result, \"numpy ë°°ì—´ ì €ì¥ ì‹¤íŒ¨\"\n",
    "\n",
    "        # ë°°ì—´ ë¡œë“œ\n",
    "        loaded_array = helper.cache_load(array_key)\n",
    "        assert loaded_array is not None, \"numpy ë°°ì—´ ë¡œë“œ ì‹¤íŒ¨\"\n",
    "        assert isinstance(loaded_array, np.ndarray), \"ë¡œë“œëœ ê°ì²´ê°€ numpy ë°°ì—´ì´ ì•„ë‹˜\"\n",
    "        assert np.array_equal(loaded_array, test_array), \"numpy ë°°ì—´ ë‚´ìš©ì´ ë‹¤ë¦„\"\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"numpy ë°°ì—´ ìºì‹œ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# 9.5 ìºì‹œ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "def test_cache_management():\n",
    "    \"\"\"ìºì‹œ ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        # ì—¬ëŸ¬ í‚¤ ìƒì„±\n",
    "        keys = []\n",
    "        for i in range(3):\n",
    "            key = helper.cache_key(f\"test_item_{i}\")\n",
    "            helper.cache_save(key, f\"data_{i}\")\n",
    "            keys.append(key)\n",
    "\n",
    "        # í‚¤ ëª©ë¡ í™•ì¸\n",
    "        all_keys = helper.cache_list_keys()\n",
    "        assert len(all_keys) >= 3, \"ì €ì¥ëœ í‚¤ ê°œìˆ˜ê°€ ë¶€ì¡±\"\n",
    "\n",
    "        # ìºì‹œ í¬ê¸° í™•ì¸\n",
    "        cache_size = helper.cache_size()\n",
    "        assert cache_size >= 3, \"ìºì‹œ í¬ê¸°ê°€ ë¶€ì¡±\"\n",
    "\n",
    "        # í‚¤ ì‚­ì œ\n",
    "        delete_result = helper.cache_delete(keys[0])\n",
    "        assert delete_result, \"í‚¤ ì‚­ì œ ì‹¤íŒ¨\"\n",
    "\n",
    "        # ì‚­ì œ í™•ì¸\n",
    "        assert not helper.cache_exists(keys[0]), \"ì‚­ì œëœ í‚¤ê°€ ì—¬ì „íˆ ì¡´ì¬\"\n",
    "\n",
    "        # ì—¬ëŸ¬ í‚¤ ì‚­ì œ\n",
    "        deleted_count = helper.cache_delete_keys(keys[1], keys[2])\n",
    "        assert deleted_count == 2, \"ì—¬ëŸ¬ í‚¤ ì‚­ì œ ê°œìˆ˜ê°€ ë§ì§€ ì•ŠìŒ\"\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"ìºì‹œ ê´€ë¦¬ ê¸°ëŠ¥ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# 9.6 ë³µì¡í•œ ê°ì²´ ìºì‹œ í…ŒìŠ¤íŠ¸\n",
    "def test_complex_object_cache():\n",
    "    \"\"\"ë³µì¡í•œ ê°ì²´ ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        # ë³µì¡í•œ ê°ì²´\n",
    "        complex_obj = {\n",
    "            'dataframe': pd.DataFrame({'x': [1, 2], 'y': [3, 4]}),\n",
    "            'array': np.array([1, 2, 3]),\n",
    "            'list': [1, 2, {'nested': 'value'}],\n",
    "            'metadata': {\n",
    "                'version': '1.0',\n",
    "                'created': '2025-07-22'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        complex_key = helper.cache_key(\"complex_object\", \"v1.0\")\n",
    "\n",
    "        # ì €ì¥\n",
    "        save_result = helper.cache_save(complex_key, complex_obj)\n",
    "        assert save_result, \"ë³µì¡í•œ ê°ì²´ ì €ì¥ ì‹¤íŒ¨\"\n",
    "\n",
    "        # ë¡œë“œ\n",
    "        loaded_obj = helper.cache_load(complex_key)\n",
    "        assert loaded_obj is not None, \"ë³µì¡í•œ ê°ì²´ ë¡œë“œ ì‹¤íŒ¨\"\n",
    "\n",
    "        # ë‚´ìš© ê²€ì¦\n",
    "        assert isinstance(loaded_obj['dataframe'], pd.DataFrame), \"DataFrame íƒ€ì… ë¶ˆì¼ì¹˜\"\n",
    "        assert isinstance(loaded_obj['array'], np.ndarray), \"numpy ë°°ì—´ íƒ€ì… ë¶ˆì¼ì¹˜\"\n",
    "        assert loaded_obj['metadata'] == complex_obj['metadata'], \"ë©”íƒ€ë°ì´í„° ë¶ˆì¼ì¹˜\"\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"ë³µì¡í•œ ê°ì²´ ìºì‹œ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# 9.7 ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "def test_cache_error_handling():\n",
    "    \"\"\"ìºì‹œ ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ ë¡œë“œ\n",
    "        non_existent_data = helper.cache_load(\"non_existent_key\")\n",
    "        assert non_existent_data is None, \"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ì— ëŒ€í•´ Noneì´ ë°˜í™˜ë˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ ì¡´ì¬ í™•ì¸\n",
    "        exists = helper.cache_exists(\"non_existent_key\")\n",
    "        assert not exists, \"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ê°€ ì¡´ì¬í•œë‹¤ê³  íŒë‹¨ë¨\"\n",
    "\n",
    "        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ ì‚­ì œ\n",
    "        delete_result = helper.cache_delete(\"non_existent_key\")\n",
    "        assert not delete_result, \"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤ ì‚­ì œê°€ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ë¨\"\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"ìºì‹œ ì—ëŸ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# run_test í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "run_test(\"numpy ë°°ì—´ ìºì‹œ\", test_numpy_cache)\n",
    "run_test(\"ìºì‹œ ê´€ë¦¬ ê¸°ëŠ¥\", test_cache_management)\n",
    "run_test(\"ë³µì¡í•œ ê°ì²´ ìºì‹œ\", test_complex_object_cache)\n",
    "run_test(\"ìºì‹œ ì—ëŸ¬ ì²˜ë¦¬\", test_cache_error_handling)\n",
    "\n",
    "# ìºì‹œ ì •ë¦¬\n",
    "helper.cache_clear()\n",
    "\n",
    "print(f\"\\nğŸ’¾ ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce59e5",
   "metadata": {
    "id": "37ce59e5"
   },
   "outputs": [],
   "source": [
    "# 9.8 í™˜ê²½ë³„ ìºì‹œ ê²½ë¡œ í…ŒìŠ¤íŠ¸\n",
    "def test_cache_path_by_environment():\n",
    "    \"\"\"í™˜ê²½ë³„ ìºì‹œ ê²½ë¡œ ì„¤ì • í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        # ìºì‹œ ì •ë¦¬\n",
    "        helper.cache_clear()\n",
    "\n",
    "        # í™˜ê²½ í™•ì¸\n",
    "        is_colab = helper._in_colab()\n",
    "\n",
    "        # ê¸°ë³¸ ê²½ë¡œ í…ŒìŠ¤íŠ¸\n",
    "        test_key = helper.cache_key(\"path_test\")\n",
    "        test_data = {\"env\": \"test\", \"path\": \"default\"}\n",
    "\n",
    "        # ì €ì¥\n",
    "        save_result = helper.cache_save(test_key, test_data)\n",
    "        assert save_result, \"ê¸°ë³¸ ê²½ë¡œ ì €ì¥ ì‹¤íŒ¨\"\n",
    "\n",
    "        # ìºì‹œ ì •ë³´ í™•ì¸ (ê²½ë¡œ ê²€ì¦)\n",
    "        # DataCatch í´ë˜ìŠ¤ì—ì„œ ì§ì ‘ ê²½ë¡œ í™•ì¸\n",
    "        from helper_c0z0c_dev import DataCatch\n",
    "        DataCatch._initialize_cache()\n",
    "        cache_file_path = DataCatch._cache_file\n",
    "\n",
    "        if is_colab:\n",
    "            # Colab í™˜ê²½ì—ì„œëŠ” Google Drive ê²½ë¡œì—¬ì•¼ í•¨\n",
    "            expected_path = \"/content/drive/MyDrive/cache.json\"\n",
    "            assert cache_file_path == expected_path, f\"Colab ê²½ë¡œ ë¶ˆì¼ì¹˜: {cache_file_path} != {expected_path}\"\n",
    "            print(f\"âœ… Colab ìºì‹œ ê²½ë¡œ í™•ì¸: {cache_file_path}\")\n",
    "        else:\n",
    "            # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” í˜„ì¬ ë””ë ‰í† ë¦¬\n",
    "            expected_path = \"cache.json\"\n",
    "            assert cache_file_path == expected_path, f\"ë¡œì»¬ ê²½ë¡œ ë¶ˆì¼ì¹˜: {cache_file_path} != {expected_path}\"\n",
    "            print(f\"âœ… ë¡œì»¬ ìºì‹œ ê²½ë¡œ í™•ì¸: {cache_file_path}\")\n",
    "\n",
    "        # ì‚¬ìš©ì ì§€ì • íŒŒì¼ í…ŒìŠ¤íŠ¸\n",
    "        custom_file = \"test_custom.json\"\n",
    "        custom_data = {\"env\": \"test\", \"path\": \"custom\"}\n",
    "        custom_key = helper.cache_key(\"custom_path_test\")\n",
    "\n",
    "        save_result_custom = helper.cache_save(custom_key, custom_data, custom_file)\n",
    "        assert save_result_custom, \"ì‚¬ìš©ì ì§€ì • ê²½ë¡œ ì €ì¥ ì‹¤íŒ¨\"\n",
    "\n",
    "        # ë¡œë“œ í…ŒìŠ¤íŠ¸\n",
    "        loaded_data = helper.cache_load(test_key)\n",
    "        loaded_custom = helper.cache_load(custom_key, custom_file)\n",
    "\n",
    "        assert loaded_data == test_data, \"ê¸°ë³¸ ê²½ë¡œ ë¡œë“œ ë°ì´í„° ë¶ˆì¼ì¹˜\"\n",
    "        assert loaded_custom == custom_data, \"ì‚¬ìš©ì ê²½ë¡œ ë¡œë“œ ë°ì´í„° ë¶ˆì¼ì¹˜\"\n",
    "\n",
    "        # ì •ë¦¬\n",
    "        helper.cache_delete(test_key)\n",
    "        helper.cache_delete(custom_key, custom_file)\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"í™˜ê²½ë³„ ìºì‹œ ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# run_test í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "run_test(\"í™˜ê²½ë³„ ìºì‹œ ê²½ë¡œ\", test_cache_path_by_environment)\n",
    "\n",
    "# í˜„ì¬ í™˜ê²½ ì •ë³´ ì¶œë ¥\n",
    "is_colab = helper._in_colab()\n",
    "env_name = \"Colab\" if is_colab else \"ë¡œì»¬\"\n",
    "print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ í™˜ê²½: {env_name}\")\n",
    "\n",
    "if is_colab:\n",
    "    print(\"ğŸ’¾ Colab ìºì‹œ ê²½ë¡œ: /content/drive/MyDrive/cache.json\")\n",
    "    print(\"ğŸ”„ Google Driveì— ìë™ ì €ì¥ìœ¼ë¡œ ì„¸ì…˜ ì¢…ë£Œ í›„ì—ë„ ë³´ì¡´\")\n",
    "else:\n",
    "    print(\"ğŸ’¾ ë¡œì»¬ ìºì‹œ ê²½ë¡œ: cache.json\")\n",
    "    print(\"ğŸ”„ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì €ì¥\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb57099",
   "metadata": {
    "id": "ebb57099"
   },
   "source": [
    "## 13. matplotlib ê¸€ë¡œë²Œ ë“±ë¡ í…ŒìŠ¤íŠ¸ (IPython í™˜ê²½)\n",
    "- reset_matplotlib() í•¨ìˆ˜ì˜ IPython.user_nsë¥¼ í†µí•œ plt ì „ì—­ ë“±ë¡ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "- Colab/Jupyter í™˜ê²½ì—ì„œì˜ ê¸€ë¡œë²Œ ìŠ¤ì½”í”„ ì²˜ë¦¬ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc6472",
   "metadata": {
    "id": "8acc6472"
   },
   "outputs": [],
   "source": [
    "def test_matplotlib_global_registration():\n",
    "    \"\"\"matplotlib ê¸€ë¡œë²Œ ë“±ë¡ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ¨ matplotlib ê¸€ë¡œë²Œ ë“±ë¡ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "        # matplotlib.pyplotì´ ì´ë¯¸ importë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
    "        import matplotlib.pyplot as original_plt\n",
    "        original_available = 'plt' in globals() or 'plt' in locals()\n",
    "\n",
    "        print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸ ì „ plt ìƒíƒœ - ë¡œì»¬ ìŠ¤ì½”í”„: {'plt' in locals()}, ê¸€ë¡œë²Œ ìŠ¤ì½”í”„: {'plt' in globals()}\")\n",
    "\n",
    "        # IPython í™˜ê²½ í™•ì¸\n",
    "        try:\n",
    "            import IPython\n",
    "            ipy = IPython.get_ipython()\n",
    "            ipython_available = ipy is not None\n",
    "            print(f\"ğŸ”¬ IPython í™˜ê²½: {ipython_available}\")\n",
    "\n",
    "            if ipython_available:\n",
    "                # IPython.user_nsì—ì„œ plt í™•ì¸\n",
    "                user_ns_before = 'plt' in ipy.user_ns\n",
    "                print(f\"ğŸ“‹ í…ŒìŠ¤íŠ¸ ì „ IPython.user_ns['plt'] ì¡´ì¬: {user_ns_before}\")\n",
    "        except ImportError:\n",
    "            ipython_available = False\n",
    "            print(\"âš ï¸ IPythonì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "        # reset_matplotlib() ì‹¤í–‰\n",
    "        print(\"ğŸ”„ reset_matplotlib() ì‹¤í–‰ ì¤‘...\")\n",
    "        result_plt = helper.reset_matplotlib()\n",
    "\n",
    "        # ê²°ê³¼ ê²€ì¦\n",
    "        assert result_plt is not None, \"reset_matplotlib()ê°€ plt ê°ì²´ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "        # IPython í™˜ê²½ì—ì„œ user_ns ë“±ë¡ í™•ì¸\n",
    "        if ipython_available:\n",
    "            user_ns_after = 'plt' in ipy.user_ns\n",
    "            print(f\"âœ… í…ŒìŠ¤íŠ¸ í›„ IPython.user_ns['plt'] ì¡´ì¬: {user_ns_after}\")\n",
    "\n",
    "            if user_ns_after:\n",
    "                # IPython.user_nsì— ë“±ë¡ëœ pltê°€ ë™ì¼í•œ ëª¨ë“ˆì¸ì§€ í™•ì¸\n",
    "                registered_plt = ipy.user_ns['plt']\n",
    "                # ë™ì¼í•œ ëª¨ë“ˆì¸ì§€ í™•ì¸ (ê°ì²´ ì§ì ‘ ë¹„êµ ëŒ€ì‹  ëª¨ë“ˆëª… ë¹„êµ)\n",
    "                assert registered_plt.__name__ == result_plt.__name__, \"IPython.user_nsì— ë“±ë¡ëœ pltì™€ ë°˜í™˜ëœ pltì˜ ëª¨ë“ˆëª…ì´ ë‹¤ë¦„\"\n",
    "                print(\"âœ… IPython.user_nsì— pltê°€ ì˜¬ë°”ë¥´ê²Œ ë“±ë¡ë¨\")\n",
    "\n",
    "                # ì‹¤ì œë¡œ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸\n",
    "                try:\n",
    "                    # ê°„ë‹¨í•œ í”Œë¡¯ í…ŒìŠ¤íŠ¸\n",
    "                    test_fig = registered_plt.figure(figsize=(1, 1))\n",
    "                    registered_plt.plot([1, 2, 3], [1, 2, 3])\n",
    "                    registered_plt.close(test_fig)\n",
    "                    print(\"âœ… IPython.user_nsì—ì„œ plt ê°ì²´ ì •ìƒ ì‘ë™\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ IPython.user_ns plt ê°ì²´ ì‚¬ìš© ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            else:\n",
    "                print(\"âš ï¸ IPython.user_nsì— pltê°€ ë“±ë¡ë˜ì§€ ì•ŠìŒ\")\n",
    "\n",
    "        # globals()ì—ë„ ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "        globals_after = 'plt' in globals()\n",
    "        print(f\"ğŸ“‹ í…ŒìŠ¤íŠ¸ í›„ globals()['plt'] ì¡´ì¬: {globals_after}\")\n",
    "\n",
    "        # ë°˜í™˜ëœ plt ê°ì²´ê°€ ìœ íš¨í•œì§€ í™•ì¸\n",
    "        assert hasattr(result_plt, 'figure'), \"ë°˜í™˜ëœ pltì— figure ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "        assert hasattr(result_plt, 'plot'), \"ë°˜í™˜ëœ pltì— plot ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "        assert hasattr(result_plt, 'show'), \"ë°˜í™˜ëœ pltì— show ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "\n",
    "        # í•œê¸€ í°íŠ¸ê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "        current_font = result_plt.rcParams.get('font.family', ['default'])\n",
    "        if isinstance(current_font, list):\n",
    "            current_font = current_font[0] if current_font else 'default'\n",
    "        print(f\"ğŸ”¤ í˜„ì¬ ì„¤ì •ëœ í°íŠ¸: {current_font}\")\n",
    "\n",
    "        # ìœ ë‹ˆì½”ë“œ ë§ˆì´ë„ˆìŠ¤ ì„¤ì • í™•ì¸\n",
    "        unicode_minus = result_plt.rcParams.get('axes.unicode_minus', True)\n",
    "        assert unicode_minus == False, \"ìœ ë‹ˆì½”ë“œ ë§ˆì´ë„ˆìŠ¤ê°€ Falseë¡œ ì„¤ì •ë˜ì§€ ì•ŠìŒ\"\n",
    "        print(\"âœ… ìœ ë‹ˆì½”ë“œ ë§ˆì´ë„ˆìŠ¤ ì„¤ì • í™•ì¸\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"matplotlib ê¸€ë¡œë²Œ ë“±ë¡ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_matplotlib_ipython_persistence():\n",
    "    \"\"\"matplotlib IPython ì§€ì†ì„± í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ’¾ matplotlib IPython ì§€ì†ì„± í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "        # IPython í™˜ê²½ì—ì„œë§Œ í…ŒìŠ¤íŠ¸\n",
    "        try:\n",
    "            import IPython\n",
    "            ipy = IPython.get_ipython()\n",
    "            if ipy is None:\n",
    "                print(\"âš ï¸ IPython í™˜ê²½ì´ ì•„ë‹ˆë¯€ë¡œ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ\")\n",
    "                return True\n",
    "        except ImportError:\n",
    "            print(\"âš ï¸ IPythonì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ\")\n",
    "            return True\n",
    "\n",
    "        # reset_matplotlib() ì‹¤í–‰\n",
    "        helper.reset_matplotlib()\n",
    "\n",
    "        # IPython.user_nsì—ì„œ pltë¥¼ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•´ë³´ê¸°\n",
    "        if 'plt' in ipy.user_ns:\n",
    "            plt_from_user_ns = ipy.user_ns['plt']\n",
    "\n",
    "            # ì‹¤ì œ í”Œë¡¯ ìƒì„± í…ŒìŠ¤íŠ¸ (ë” ê°„ë‹¨í•˜ê²Œ)\n",
    "            try:\n",
    "                import numpy as np\n",
    "                x = np.array([1, 2, 3, 4, 5])\n",
    "                y = np.array([2, 4, 1, 5, 3])\n",
    "\n",
    "                # Figure ìƒì„±ê³¼ í”Œë¡¯ ê·¸ë¦¬ê¸°\n",
    "                fig, ax = plt_from_user_ns.subplots(figsize=(6, 4))\n",
    "                line, = ax.plot(x, y, 'o-', label='í…ŒìŠ¤íŠ¸ ë°ì´í„°')\n",
    "                ax.set_title('í•œê¸€ ì œëª© í…ŒìŠ¤íŠ¸')\n",
    "                ax.set_xlabel('Xì¶• (í•œê¸€)')\n",
    "                ax.set_ylabel('Yì¶• (í•œê¸€)')\n",
    "                ax.legend()\n",
    "                ax.grid(True)\n",
    "\n",
    "                # í”Œë¡¯ ì •ìƒ ìƒì„± í™•ì¸\n",
    "                lines = ax.get_lines()\n",
    "                assert len(lines) > 0, \"ë¼ì¸ í”Œë¡¯ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "                # í•œê¸€ í…ìŠ¤íŠ¸ ì„¤ì • í™•ì¸\n",
    "                title_text = ax.get_title()\n",
    "                assert 'í•œê¸€' in title_text, \"í•œê¸€ ì œëª©ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ\"\n",
    "\n",
    "                # Figure ê°ì²´ ë‹«ê¸°\n",
    "                plt_from_user_ns.close(fig)\n",
    "                print(\"âœ… IPython.user_nsì—ì„œ pltë¡œ í•œê¸€ í”Œë¡¯ ì •ìƒ ìƒì„±\")\n",
    "\n",
    "                return True\n",
    "\n",
    "            except Exception as plot_error:\n",
    "                print(f\"âš ï¸ í”Œë¡¯ ìƒì„± ì¤‘ ì˜¤ë¥˜: {plot_error}\")\n",
    "                # í”Œë¡¯ ìƒì„± ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ê¸°ëŠ¥ì€ ì‘ë™í•œë‹¤ê³  íŒë‹¨\n",
    "                return True\n",
    "        else:\n",
    "            raise Exception(\"IPython.user_nsì— pltê°€ ë“±ë¡ë˜ì§€ ì•ŠìŒ\")\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"matplotlib IPython ì§€ì†ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_matplotlib_global_accessibility():\n",
    "    \"\"\"matplotlib ì „ì—­ ì ‘ê·¼ì„± í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸŒ matplotlib ì „ì—­ ì ‘ê·¼ì„± í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "        # reset_matplotlib() ì‹¤í–‰\n",
    "        helper.reset_matplotlib()\n",
    "\n",
    "        # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ plt ì ‘ê·¼ ì‹œë„\n",
    "        access_methods = []\n",
    "\n",
    "        # 1. IPython.user_nsë¥¼ í†µí•œ ì ‘ê·¼\n",
    "        try:\n",
    "            import IPython\n",
    "            ipy = IPython.get_ipython()\n",
    "            if ipy is not None and 'plt' in ipy.user_ns:\n",
    "                plt_ipython = ipy.user_ns['plt']\n",
    "                access_methods.append((\"IPython.user_ns\", plt_ipython))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # 2. globals()ë¥¼ í†µí•œ ì ‘ê·¼\n",
    "        if 'plt' in globals():\n",
    "            plt_globals = globals()['plt']\n",
    "            access_methods.append((\"globals()\", plt_globals))\n",
    "\n",
    "        # 3. ì§ì ‘ importë¥¼ í†µí•œ ì ‘ê·¼\n",
    "        import matplotlib.pyplot as plt_direct\n",
    "        access_methods.append((\"direct import\", plt_direct))\n",
    "\n",
    "        print(f\"ğŸ“‹ plt ì ‘ê·¼ ë°©ë²• {len(access_methods)}ê°€ì§€ í™•ì¸:\")\n",
    "        for method_name, plt_obj in access_methods:\n",
    "            print(f\"  - {method_name}: {type(plt_obj)}\")\n",
    "\n",
    "            # ê° ë°©ë²•ìœ¼ë¡œ ì–»ì€ pltê°€ ë™ì¼í•œ ëª¨ë“ˆì¸ì§€ í™•ì¸\n",
    "            assert hasattr(plt_obj, 'figure'), f\"{method_name}ìœ¼ë¡œ ì–»ì€ pltì— figure ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "\n",
    "        # ëª¨ë“  ë°©ë²•ìœ¼ë¡œ ì–»ì€ pltê°€ ë™ì¼í•œ ëª¨ë“ˆì„ ì°¸ì¡°í•˜ëŠ”ì§€ í™•ì¸\n",
    "        if len(access_methods) > 1:\n",
    "            base_module = access_methods[0][1].__class__.__module__\n",
    "            for method_name, plt_obj in access_methods[1:]:\n",
    "                assert plt_obj.__class__.__module__ == base_module, f\"{method_name}ì˜ pltê°€ ë‹¤ë¥¸ ëª¨ë“ˆì„ ì°¸ì¡°í•¨\"\n",
    "\n",
    "        print(\"âœ… ëª¨ë“  ì ‘ê·¼ ë°©ë²•ìœ¼ë¡œ ë™ì¼í•œ matplotlib.pyplot ëª¨ë“ˆ í™•ì¸\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"matplotlib ì „ì—­ ì ‘ê·¼ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# matplotlib ê¸€ë¡œë²Œ ë“±ë¡ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ¨ matplotlib ê¸€ë¡œë²Œ ë“±ë¡ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "run_test(\"matplotlib ê¸€ë¡œë²Œ ë“±ë¡\", test_matplotlib_global_registration)\n",
    "run_test(\"matplotlib IPython ì§€ì†ì„±\", test_matplotlib_ipython_persistence)\n",
    "run_test(\"matplotlib ì „ì—­ ì ‘ê·¼ì„±\", test_matplotlib_global_accessibility)\n",
    "print(\"ğŸ¨ matplotlib ê¸€ë¡œë²Œ ë“±ë¡ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120e7573",
   "metadata": {
    "id": "120e7573"
   },
   "source": [
    "## 12. DataFrame ì»¤ë°‹ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "- pd_root, set_pd_root_base, pd_commit, pd_commit_list, pd_checkout, pd_read_csv ë“± ê²½ë¡œ/ì»¤ë°‹ ê´€ë ¨ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf325af",
   "metadata": {
    "id": "3bf325af"
   },
   "outputs": [],
   "source": [
    "helper.pd_commit_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8758a",
   "metadata": {
    "id": "8ec8758a"
   },
   "outputs": [],
   "source": [
    "### helper ë° DataFrame ì»¤ë°‹ ê¸°ëŠ¥ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from helper_c0z0c_dev import pd_commit, pd_commit_list, pd_checkout, pd_commit_rm\n",
    "\n",
    "# ì„ì‹œ ì»¤ë°‹ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# ìƒ˜í”Œ DataFrame\n",
    "df = pd.DataFrame({'a': [1, 2, 3]})\n",
    "\n",
    "# pd_commit ë° pd_commit_list í…ŒìŠ¤íŠ¸\n",
    "pd_commit(df, \"test_msg\", commit_dir=temp_dir)\n",
    "commits = pd_commit_list(commit_dir=temp_dir)\n",
    "assert not commits.empty, \"ì»¤ë°‹ ëª©ë¡ì´ ë¹„ì–´ ìˆì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤\"\n",
    "assert commits.loc[0, 'msg'] == \"test_msg\", \"ì»¤ë°‹ ë©”ì‹œì§€ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤\"\n",
    "\n",
    "# ì¸ë±ìŠ¤ë¡œ pd_checkout í…ŒìŠ¤íŠ¸\n",
    "df2 = pd_checkout(0, commit_dir=temp_dir)\n",
    "assert df2.equals(df), \"ì¸ë±ìŠ¤ë¡œ ë³µì›ëœ DataFrameì´ ì›ë³¸ê³¼ ë‹¤ë¦…ë‹ˆë‹¤\"\n",
    "\n",
    "# í•´ì‹œë¡œ pd_checkout í…ŒìŠ¤íŠ¸\n",
    "hash_str = commits.loc[0, 'hash']\n",
    "df3 = pd_checkout(hash_str, commit_dir=temp_dir)\n",
    "assert df3.equals(df), \"í•´ì‹œë¡œ ë³µì›ëœ DataFrameì´ ì›ë³¸ê³¼ ë‹¤ë¦…ë‹ˆë‹¤\"\n",
    "\n",
    "# pd_commit_rm í…ŒìŠ¤íŠ¸ ë° ì‚­ì œ í™•ì¸\n",
    "pd_commit_rm(0, commit_dir=temp_dir)\n",
    "commits_after_rm = pd_commit_list(commit_dir=temp_dir)\n",
    "assert commits_after_rm.empty, \"ì‚­ì œ í›„ì—ë„ ì»¤ë°‹ ëª©ë¡ì´ ë¹„ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤\"\n",
    "\n",
    "# DataFrame ë©”ì„œë“œ ë°”ì¸ë”© í…ŒìŠ¤íŠ¸\n",
    "df_new = pd.DataFrame({'b': [4, 5]})\n",
    "df_new.commit(\"df_method\", commit_dir=temp_dir)\n",
    "df_list = pd.DataFrame.commit_list(commit_dir=temp_dir)\n",
    "assert df_list.loc[0, 'msg'] == \"df_method\", \"DataFrame.commit ë©”ì‹œì§€ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤\"\n",
    "df_checked = pd.DataFrame.checkout(0, commit_dir=temp_dir)\n",
    "assert df_checked.equals(df_new), \"DataFrame.checkout ê²°ê³¼ê°€ ì›ë³¸ê³¼ ë‹¤ë¦…ë‹ˆë‹¤\"\n",
    "pd.DataFrame.commit_rm(0, commit_dir=temp_dir)\n",
    "assert pd.DataFrame.commit_list(commit_dir=temp_dir).empty, \"DataFrame.commit_rmì´ ì»¤ë°‹ì„ ì‚­ì œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤\"\n",
    "\n",
    "# ì •ë¦¬\n",
    "shutil.rmtree(temp_dir)\n",
    "print(\"âœ… ëª¨ë“  helper ë° DataFrame ì»¤ë°‹ í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd8c17",
   "metadata": {},
   "source": [
    "## 13. aihub.or.kr dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.1 AIHubShell í´ë˜ìŠ¤ ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "def test_aihub_shell_initialization():\n",
    "    \"\"\"AIHubShell í´ë˜ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ¤– AIHubShell í´ë˜ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        # helper ëª¨ë“ˆì—ì„œ AIHubShell ì„í¬íŠ¸\n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        \n",
    "        # ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "        aihub = AIHubShell()\n",
    "        \n",
    "        # ê¸°ë³¸ ì†ì„± í™•ì¸\n",
    "        assert hasattr(aihub, 'BASE_URL'), \"BASE_URL ì†ì„±ì´ ì—†ìŒ\"\n",
    "        assert hasattr(aihub, 'debug'), \"debug ì†ì„±ì´ ì—†ìŒ\"\n",
    "        assert hasattr(aihub, 'download_dir'), \"download_dir ì†ì„±ì´ ì—†ìŒ\"\n",
    "        \n",
    "        # URL í™•ì¸\n",
    "        assert aihub.BASE_URL == \"https://api.aihub.or.kr\", f\"BASE_URLì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {aihub.BASE_URL}\"\n",
    "        \n",
    "        # ê¸°ë³¸ê°’ í™•ì¸\n",
    "        assert aihub.debug == False, \"debug ê¸°ë³¸ê°’ì´ Falseê°€ ì•„ë‹˜\"\n",
    "        assert aihub.download_dir == \".\", f\"download_dir ê¸°ë³¸ê°’ì´ '.'ê°€ ì•„ë‹˜: {aihub.download_dir}\"\n",
    "        \n",
    "        print(f\"âœ… BASE_URL: {aihub.BASE_URL}\")\n",
    "        print(f\"âœ… debug: {aihub.debug}\")\n",
    "        print(f\"âœ… download_dir: {aihub.download_dir}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_initialization_with_params():\n",
    "    \"\"\"AIHubShell í´ë˜ìŠ¤ ë§¤ê°œë³€ìˆ˜ í¬í•¨ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ”§ AIHubShell ë§¤ê°œë³€ìˆ˜ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        \n",
    "        # ë§¤ê°œë³€ìˆ˜ë¥¼ í¬í•¨í•œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "        test_dir = \"./test_download\"\n",
    "        aihub = AIHubShell(debug=True, download_dir=test_dir)\n",
    "        \n",
    "        # ì„¤ì •ëœ ê°’ í™•ì¸\n",
    "        assert aihub.debug == True, \"debug ê°’ì´ Trueë¡œ ì„¤ì •ë˜ì§€ ì•ŠìŒ\"\n",
    "        assert aihub.download_dir == test_dir, f\"download_dirê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„: {aihub.download_dir}\"\n",
    "        \n",
    "        # í•„ìˆ˜ ë©”ì„œë“œ ì¡´ì¬ í™•ì¸\n",
    "        required_methods = ['help', 'print_usage', 'list_info', 'list_search', 'download_dataset']\n",
    "        \n",
    "        for method in required_methods:\n",
    "            assert hasattr(aihub, method), f\"{method} ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "            assert callable(getattr(aihub, method)), f\"{method}ê°€ í˜¸ì¶œ ê°€ëŠ¥í•˜ì§€ ì•ŠìŒ\"\n",
    "        \n",
    "        print(f\"âœ… debug: {aihub.debug}\")\n",
    "        print(f\"âœ… download_dir: {aihub.download_dir}\")\n",
    "        print(f\"âœ… í•„ìˆ˜ ë©”ì„œë“œ {len(required_methods)}ê°œ í™•ì¸ ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell ë§¤ê°œë³€ìˆ˜ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_help_method():\n",
    "    \"\"\"AIHubShell help ë©”ì„œë“œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ“– AIHubShell help ë©”ì„œë“œ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell()\n",
    "        \n",
    "        # help ë©”ì„œë“œ ì‹¤í–‰ (ì¶œë ¥ë§Œ í™•ì¸)\n",
    "        print(\"ğŸ” help() ë©”ì„œë“œ ì‹¤í–‰:\")\n",
    "        aihub.help()\n",
    "        \n",
    "        # ì—ëŸ¬ ì—†ì´ ì‹¤í–‰ë˜ì—ˆìœ¼ë©´ ì„±ê³µ\n",
    "        print(\"âœ… help() ë©”ì„œë“œ ì •ìƒ ì‹¤í–‰\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell help ë©”ì„œë“œ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# AIHubShell í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ¤– AIHubShell í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "run_test(\"AIHubShell ê¸°ë³¸ ì´ˆê¸°í™”\", test_aihub_shell_initialization)\n",
    "run_test(\"AIHubShell ë§¤ê°œë³€ìˆ˜ ì´ˆê¸°í™”\", test_aihub_shell_initialization_with_params)\n",
    "run_test(\"AIHubShell help ë©”ì„œë“œ\", test_aihub_shell_help_method)\n",
    "print(\"ğŸ¤– AIHubShell í´ë˜ìŠ¤ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79203810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.2 AIHubShell API ì—°ê²° í…ŒìŠ¤íŠ¸ (ëª¨ì˜ í…ŒìŠ¤íŠ¸)\n",
    "def test_aihub_shell_api_methods():\n",
    "    \"\"\"AIHubShell API ë©”ì„œë“œ ì¡´ì¬ ë° í˜¸ì¶œ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ API í˜¸ì¶œ ì—†ì´)\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸŒ AIHubShell API ë©”ì„œë“œ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell(debug=False)  # debug=Falseë¡œ ì„¤ì •í•˜ì—¬ ì¶œë ¥ ìµœì†Œí™”\n",
    "        \n",
    "        # API URL êµ¬ì„± í™•ì¸\n",
    "        expected_urls = {\n",
    "            'BASE_URL': 'https://api.aihub.or.kr',\n",
    "            'LOGIN_URL': 'https://api.aihub.or.kr/api/keyValidate.do',\n",
    "            'BASE_DOWNLOAD_URL': 'https://api.aihub.or.kr/down/0.5',\n",
    "            'MANUAL_URL': 'https://api.aihub.or.kr/info/api.do',\n",
    "            'BASE_FILETREE_URL': 'https://api.aihub.or.kr/info',\n",
    "            'DATASET_URL': 'https://api.aihub.or.kr/info/dataset.do'\n",
    "        }\n",
    "        \n",
    "        for attr, expected_url in expected_urls.items():\n",
    "            actual_url = getattr(aihub, attr)\n",
    "            assert actual_url == expected_url, f\"{attr}ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {actual_url} != {expected_url}\"\n",
    "            print(f\"âœ… {attr}: {actual_url}\")\n",
    "        \n",
    "        # ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸ (ì‹¤ì œ í˜¸ì¶œ ì—†ì´)\n",
    "        import inspect\n",
    "        \n",
    "        # list_info ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜\n",
    "        list_info_sig = inspect.signature(aihub.list_info)\n",
    "        list_info_params = list(list_info_sig.parameters.keys())\n",
    "        expected_params = ['datasetkey', 'datasetname']\n",
    "        for param in expected_params:\n",
    "            assert param in list_info_params, f\"list_infoì— {param} ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìŒ\"\n",
    "        \n",
    "        # list_search ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜\n",
    "        list_search_sig = inspect.signature(aihub.list_search)\n",
    "        list_search_params = list(list_search_sig.parameters.keys())\n",
    "        expected_search_params = ['datasetname', 'tree']\n",
    "        for param in expected_search_params:\n",
    "            assert param in list_search_params, f\"list_searchì— {param} ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìŒ\"\n",
    "        \n",
    "        # download_dataset ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜\n",
    "        download_sig = inspect.signature(aihub.download_dataset)\n",
    "        download_params = list(download_sig.parameters.keys())\n",
    "        expected_download_params = ['apikey', 'datasetkey', 'filekeys']\n",
    "        for param in expected_download_params:\n",
    "            assert param in download_params, f\"download_datasetì— {param} ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìŒ\"\n",
    "        \n",
    "        print(\"âœ… ëª¨ë“  API ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸ ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell API ë©”ì„œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_url_construction():\n",
    "    \"\"\"AIHubShell URL êµ¬ì„± ë¡œì§ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ”— AIHubShell URL êµ¬ì„± í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell()\n",
    "        \n",
    "        # ê¸°ë³¸ URL í…ŒìŠ¤íŠ¸\n",
    "        base_url = aihub.BASE_URL\n",
    "        assert base_url.startswith('https://'), \"BASE_URLì´ HTTPSë¡œ ì‹œì‘í•˜ì§€ ì•ŠìŒ\"\n",
    "        assert 'aihub.or.kr' in base_url, \"aihub.or.kr ë„ë©”ì¸ì´ í¬í•¨ë˜ì§€ ì•ŠìŒ\"\n",
    "        \n",
    "        # ê° URLì´ base_urlì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "        urls_to_check = [\n",
    "            ('LOGIN_URL', '/api/keyValidate.do'),\n",
    "            ('BASE_DOWNLOAD_URL', '/down/0.5'),\n",
    "            ('MANUAL_URL', '/info/api.do'),\n",
    "            ('BASE_FILETREE_URL', '/info'),\n",
    "            ('DATASET_URL', '/info/dataset.do')\n",
    "        ]\n",
    "        \n",
    "        for attr_name, expected_path in urls_to_check:\n",
    "            full_url = getattr(aihub, attr_name)\n",
    "            assert full_url.startswith(base_url), f\"{attr_name}ì´ BASE_URLë¡œ ì‹œì‘í•˜ì§€ ì•ŠìŒ\"\n",
    "            assert full_url.endswith(expected_path), f\"{attr_name}ì´ ì˜ˆìƒ ê²½ë¡œë¡œ ëë‚˜ì§€ ì•ŠìŒ\"\n",
    "            print(f\"âœ… {attr_name}: ê²½ë¡œ êµ¬ì„± í™•ì¸\")\n",
    "        \n",
    "        # ë™ì  URL ìƒì„± í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë©”ì„œë“œ ë‚´ë¶€ ë¡œì§)\n",
    "        test_datasetkey = 123\n",
    "        expected_filetree_url = f\"{aihub.BASE_FILETREE_URL}/{test_datasetkey}.do\"\n",
    "        expected_download_url = f\"{aihub.BASE_DOWNLOAD_URL}/{test_datasetkey}.do\"\n",
    "        \n",
    "        print(f\"âœ… ë™ì  URL ì˜ˆì‹œ:\")\n",
    "        print(f\"  - íŒŒì¼íŠ¸ë¦¬: {expected_filetree_url}\")\n",
    "        print(f\"  - ë‹¤ìš´ë¡œë“œ: {expected_download_url}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell URL êµ¬ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_error_handling():\n",
    "    \"\"\"AIHubShell ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"âš ï¸ AIHubShell ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell(debug=False)\n",
    "        \n",
    "        # ì˜ëª»ëœ ë§¤ê°œë³€ìˆ˜ë¡œ ë©”ì„œë“œ í˜¸ì¶œ ì‹œ ì—ëŸ¬ ì²˜ë¦¬ í™•ì¸\n",
    "        # (ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í˜¸ì¶œì€ í•˜ì§€ ì•Šê³ , ë§¤ê°œë³€ìˆ˜ ê²€ì¦ë§Œ)\n",
    "        \n",
    "        # list_info with invalid datasetkey type (should not raise exception immediately)\n",
    "        try:\n",
    "            # ì´ ë©”ì„œë“œë“¤ì€ ë‚´ë¶€ì—ì„œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ì„ í•˜ë¯€ë¡œ ì‹¤ì œë¡œëŠ” ì‹¤í–‰í•˜ì§€ ì•ŠìŒ\n",
    "            # ëŒ€ì‹  ë©”ì„œë“œê°€ ì¡´ì¬í•˜ê³  í˜¸ì¶œ ê°€ëŠ¥í•œì§€ë§Œ í™•ì¸\n",
    "            callable(aihub.list_info)\n",
    "            callable(aihub.list_search)\n",
    "            callable(aihub.download_dataset)\n",
    "            print(\"âœ… ëª¨ë“  ë©”ì„œë“œê°€ í˜¸ì¶œ ê°€ëŠ¥í•¨\")\n",
    "            \n",
    "            # merge_parts, merge_all_parts ë©”ì„œë“œ ì¡´ì¬ í™•ì¸\n",
    "            assert hasattr(aihub, 'merge_parts'), \"merge_parts ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "            assert hasattr(aihub, 'merge_all_parts'), \"merge_all_parts ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "            print(\"âœ… íŒŒì¼ ë³‘í•© ë©”ì„œë“œ ì¡´ì¬ í™•ì¸\")\n",
    "            \n",
    "        except Exception as method_error:\n",
    "            print(f\"âš ï¸ ë©”ì„œë“œ í˜¸ì¶œ ì¤‘ ì˜ˆìƒëœ ì—ëŸ¬: {method_error}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# AIHubShell API í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸŒ AIHubShell API ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "run_test(\"AIHubShell API ë©”ì„œë“œ\", test_aihub_shell_api_methods)\n",
    "run_test(\"AIHubShell URL êµ¬ì„±\", test_aihub_shell_url_construction)\n",
    "run_test(\"AIHubShell ì—ëŸ¬ ì²˜ë¦¬\", test_aihub_shell_error_handling)\n",
    "print(\"ğŸŒ AIHubShell API ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da54246",
   "metadata": {
    "id": "9da54246"
   },
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
    "total_tests = len(test_results)\n",
    "passed_tests = len([r for r in test_results if r['status'] in ['ì„±ê³µ', 'PASS']])\n",
    "failed_tests = len([r for r in test_results if r['status'] in ['ì‹¤íŒ¨', 'FAIL']])\n",
    "\n",
    "print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê°„ë‹¨ ìš”ì•½\")\n",
    "print(f\"ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ\")\n",
    "print(f\"ì„±ê³µ: {passed_tests}ê°œ âœ…\")\n",
    "print(f\"ì‹¤íŒ¨: {failed_tests}ê°œ âŒ\")\n",
    "if total_tests > 0:\n",
    "    print(f\"ì„±ê³µë¥ : {passed_tests/total_tests*100:.1f}%\")\n",
    "\n",
    "if failed_tests > 0:\n",
    "    print(f\"\\nì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:\")\n",
    "    for result in test_results:\n",
    "        if result['status'] in ['ì‹¤íŒ¨', 'FAIL']:\n",
    "            print(f\"- {result['test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56826d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.3 AIHubShell ë©”ì„œë“œë³„ ìƒì„¸ í…ŒìŠ¤íŠ¸\n",
    "def test_aihub_shell_print_usage():\n",
    "    \"\"\"AIHubShell print_usage ë©”ì„œë“œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ“– AIHubShell print_usage ë©”ì„œë“œ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell(debug=False)\n",
    "        \n",
    "        # print_usage ë©”ì„œë“œ ì¡´ì¬ í™•ì¸\n",
    "        assert hasattr(aihub, 'print_usage'), \"print_usage ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "        assert callable(aihub.print_usage), \"print_usageê°€ í˜¸ì¶œ ê°€ëŠ¥í•˜ì§€ ì•ŠìŒ\"\n",
    "        \n",
    "        # ë©”ì„œë“œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ API í˜¸ì¶œì€ í•˜ì§€ ì•Šê³  êµ¬ì¡°ë§Œ í™•ì¸)\n",
    "        print(\"âœ… print_usage ë©”ì„œë“œ ì¡´ì¬ ë° í˜¸ì¶œ ê°€ëŠ¥í•¨ í™•ì¸\")\n",
    "        \n",
    "        # requests ëª¨ë“ˆì´ importë˜ì—ˆëŠ”ì§€ í™•ì¸ (AIHubShellì´ ì‚¬ìš©)\n",
    "        try:\n",
    "            import requests\n",
    "            print(\"âœ… requests ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "        except ImportError:\n",
    "            print(\"âš ï¸ requests ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ - AIHubShell ê¸°ëŠ¥ ì œí•œë¨\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell print_usage í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_file_merge_methods():\n",
    "    \"\"\"AIHubShell íŒŒì¼ ë³‘í•© ë©”ì„œë“œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ”„ AIHubShell íŒŒì¼ ë³‘í•© ë©”ì„œë“œ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell()\n",
    "        \n",
    "        # íŒŒì¼ ë³‘í•© ê´€ë ¨ ë©”ì„œë“œ ì¡´ì¬ í™•ì¸\n",
    "        merge_methods = ['merge_parts', 'merge_all_parts']\n",
    "        \n",
    "        for method in merge_methods:\n",
    "            assert hasattr(aihub, method), f\"{method} ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "            assert callable(getattr(aihub, method)), f\"{method}ê°€ í˜¸ì¶œ ê°€ëŠ¥í•˜ì§€ ì•ŠìŒ\"\n",
    "            print(f\"âœ… {method} ë©”ì„œë“œ ì¡´ì¬ í™•ì¸\")\n",
    "        \n",
    "        # merge_parts ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸\n",
    "        import inspect\n",
    "        merge_parts_sig = inspect.signature(aihub.merge_parts)\n",
    "        merge_parts_params = list(merge_parts_sig.parameters.keys())\n",
    "        assert 'target_dir' in merge_parts_params, \"merge_partsì— target_dir ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìŒ\"\n",
    "        \n",
    "        # merge_all_parts ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸\n",
    "        merge_all_sig = inspect.signature(aihub.merge_all_parts)\n",
    "        merge_all_params = list(merge_all_sig.parameters.keys())\n",
    "        assert 'base_path' in merge_all_params, \"merge_all_partsì— base_path ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìŒ\"\n",
    "        \n",
    "        print(\"âœ… íŒŒì¼ ë³‘í•© ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸ ì™„ë£Œ\")\n",
    "        \n",
    "        # pathlib.Path ì‚¬ìš© í™•ì¸\n",
    "        from pathlib import Path\n",
    "        assert Path, \"pathlib.Path ì‚¬ìš© ê°€ëŠ¥\"\n",
    "        print(\"âœ… pathlib.Path ì˜ì¡´ì„± í™•ì¸\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell íŒŒì¼ ë³‘í•© ë©”ì„œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_download_dataset_structure():\n",
    "    \"\"\"AIHubShell download_dataset ë©”ì„œë“œ êµ¬ì¡° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ“¥ AIHubShell download_dataset êµ¬ì¡° í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell(download_dir=\"./test_download\")\n",
    "        \n",
    "        # download_dataset ë©”ì„œë“œ ì¡´ì¬ í™•ì¸\n",
    "        assert hasattr(aihub, 'download_dataset'), \"download_dataset ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "        assert callable(aihub.download_dataset), \"download_datasetê°€ í˜¸ì¶œ ê°€ëŠ¥í•˜ì§€ ì•ŠìŒ\"\n",
    "        \n",
    "        # ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸\n",
    "        import inspect\n",
    "        download_sig = inspect.signature(aihub.download_dataset)\n",
    "        download_params = list(download_sig.parameters.keys())\n",
    "        \n",
    "        expected_params = ['apikey', 'datasetkey', 'filekeys']\n",
    "        for param in expected_params:\n",
    "            assert param in download_params, f\"download_datasetì— {param} ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìŒ\"\n",
    "        \n",
    "        # ê¸°ë³¸ê°’ í™•ì¸\n",
    "        filekeys_param = download_sig.parameters['filekeys']\n",
    "        assert filekeys_param.default == \"all\", \"filekeys ê¸°ë³¸ê°’ì´ 'all'ì´ ì•„ë‹˜\"\n",
    "        \n",
    "        print(\"âœ… download_dataset ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸\")\n",
    "        \n",
    "        # download_dir ì„¤ì • í™•ì¸\n",
    "        assert aihub.download_dir == \"./test_download\", \"download_dir ì„¤ì •ì´ ë°˜ì˜ë˜ì§€ ì•ŠìŒ\"\n",
    "        print(f\"âœ… download_dir ì„¤ì •: {aihub.download_dir}\")\n",
    "        \n",
    "        # í•„ìš”í•œ ëª¨ë“ˆë“¤ í™•ì¸\n",
    "        required_modules = ['tarfile', 'signal', 'shutil', 'datetime']\n",
    "        for module_name in required_modules:\n",
    "            try:\n",
    "                __import__(module_name)\n",
    "                print(f\"âœ… {module_name} ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "            except ImportError:\n",
    "                raise Exception(f\"{module_name} ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ìŒ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell download_dataset êµ¬ì¡° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_list_methods():\n",
    "    \"\"\"AIHubShell list_info, list_search ë©”ì„œë“œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ“‹ AIHubShell ë¦¬ìŠ¤íŠ¸ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell()\n",
    "        \n",
    "        # list_info ë©”ì„œë“œ í™•ì¸\n",
    "        assert hasattr(aihub, 'list_info'), \"list_info ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "        assert callable(aihub.list_info), \"list_infoê°€ í˜¸ì¶œ ê°€ëŠ¥í•˜ì§€ ì•ŠìŒ\"\n",
    "        \n",
    "        # list_search ë©”ì„œë“œ í™•ì¸\n",
    "        assert hasattr(aihub, 'list_search'), \"list_search ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "        assert callable(aihub.list_search), \"list_searchê°€ í˜¸ì¶œ ê°€ëŠ¥í•˜ì§€ ì•ŠìŒ\"\n",
    "        \n",
    "        # ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸\n",
    "        import inspect\n",
    "        \n",
    "        # list_info ì‹œê·¸ë‹ˆì²˜\n",
    "        list_info_sig = inspect.signature(aihub.list_info)\n",
    "        list_info_params = list(list_info_sig.parameters.keys())\n",
    "        \n",
    "        expected_info_params = ['datasetkey', 'datasetname']\n",
    "        for param in expected_info_params:\n",
    "            assert param in list_info_params, f\"list_infoì— {param} ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìŒ\"\n",
    "        \n",
    "        # ê¸°ë³¸ê°’ í™•ì¸\n",
    "        for param_name in expected_info_params:\n",
    "            param = list_info_sig.parameters[param_name]\n",
    "            assert param.default is None, f\"list_infoì˜ {param_name} ê¸°ë³¸ê°’ì´ Noneì´ ì•„ë‹˜\"\n",
    "        \n",
    "        # list_search ì‹œê·¸ë‹ˆì²˜\n",
    "        list_search_sig = inspect.signature(aihub.list_search)\n",
    "        list_search_params = list(list_search_sig.parameters.keys())\n",
    "        \n",
    "        expected_search_params = ['datasetname', 'tree']\n",
    "        for param in expected_search_params:\n",
    "            assert param in list_search_params, f\"list_searchì— {param} ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìŒ\"\n",
    "        \n",
    "        # tree ê¸°ë³¸ê°’ í™•ì¸\n",
    "        tree_param = list_search_sig.parameters['tree']\n",
    "        assert tree_param.default == False, \"list_searchì˜ tree ê¸°ë³¸ê°’ì´ Falseê°€ ì•„ë‹˜\"\n",
    "        \n",
    "        print(\"âœ… list_info, list_search ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸ ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell ë¦¬ìŠ¤íŠ¸ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_url_constants():\n",
    "    \"\"\"AIHubShell URL ìƒìˆ˜ ì •í™•ì„± í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸŒ AIHubShell URL ìƒìˆ˜ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell()\n",
    "        \n",
    "        # ëª¨ë“  URL ìƒìˆ˜ í™•ì¸\n",
    "        url_constants = {\n",
    "            'BASE_URL': 'https://api.aihub.or.kr',\n",
    "            'LOGIN_URL': 'https://api.aihub.or.kr/api/keyValidate.do',\n",
    "            'BASE_DOWNLOAD_URL': 'https://api.aihub.or.kr/down/0.5',\n",
    "            'MANUAL_URL': 'https://api.aihub.or.kr/info/api.do',\n",
    "            'BASE_FILETREE_URL': 'https://api.aihub.or.kr/info',\n",
    "            'DATASET_URL': 'https://api.aihub.or.kr/info/dataset.do'\n",
    "        }\n",
    "        \n",
    "        for attr_name, expected_url in url_constants.items():\n",
    "            actual_url = getattr(aihub, attr_name)\n",
    "            assert actual_url == expected_url, f\"{attr_name}ì´ ì˜ˆìƒê°’ê³¼ ë‹¤ë¦„: {actual_url} != {expected_url}\"\n",
    "            print(f\"âœ… {attr_name}: {actual_url}\")\n",
    "        \n",
    "        # URL í˜•ì‹ ê²€ì¦\n",
    "        for attr_name, url in url_constants.items():\n",
    "            assert url.startswith('https://'), f\"{attr_name}ì´ HTTPSë¡œ ì‹œì‘í•˜ì§€ ì•ŠìŒ\"\n",
    "            assert 'aihub.or.kr' in url, f\"{attr_name}ì— aihub.or.kr ë„ë©”ì¸ì´ ì—†ìŒ\"\n",
    "        \n",
    "        # ë™ì  URL ìƒì„± íŒ¨í„´ í…ŒìŠ¤íŠ¸\n",
    "        test_datasetkey = 576\n",
    "        expected_filetree = f\"{aihub.BASE_FILETREE_URL}/{test_datasetkey}.do\"\n",
    "        expected_download = f\"{aihub.BASE_DOWNLOAD_URL}/{test_datasetkey}.do\"\n",
    "        \n",
    "        print(f\"âœ… ë™ì  URL íŒ¨í„´:\")\n",
    "        print(f\"  - íŒŒì¼íŠ¸ë¦¬: {expected_filetree}\")\n",
    "        print(f\"  - ë‹¤ìš´ë¡œë“œ: {expected_download}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell URL ìƒìˆ˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# AIHubShell ë©”ì„œë“œë³„ ìƒì„¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ¤– AIHubShell ë©”ì„œë“œë³„ ìƒì„¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "run_test(\"AIHubShell print_usage\", test_aihub_shell_print_usage)\n",
    "run_test(\"AIHubShell íŒŒì¼ ë³‘í•© ë©”ì„œë“œ\", test_aihub_shell_file_merge_methods)\n",
    "run_test(\"AIHubShell download_dataset êµ¬ì¡°\", test_aihub_shell_download_dataset_structure)\n",
    "run_test(\"AIHubShell ë¦¬ìŠ¤íŠ¸ ë©”ì„œë“œ\", test_aihub_shell_list_methods)\n",
    "run_test(\"AIHubShell URL ìƒìˆ˜\", test_aihub_shell_url_constants)\n",
    "print(\"ğŸ¤– AIHubShell ë©”ì„œë“œë³„ ìƒì„¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1fae4",
   "metadata": {
    "id": "39f1fae4"
   },
   "source": [
    "## ğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edb266",
   "metadata": {
    "id": "d0edb266"
   },
   "outputs": [],
   "source": [
    "# ğŸ ìµœì¢… í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ (ì¦‰ì‹œ ì‹¤í–‰)\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "print(\"ğŸ¯ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
    "\n",
    "# ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘\n",
    "try:\n",
    "    helper_version = helper.__version__\n",
    "except:\n",
    "    helper_version = \"v2.4.0\"\n",
    "\n",
    "total_tests = len(test_results)\n",
    "failed_tests = len([r for r in test_results if r['status'] in ['ì‹¤íŒ¨', 'FAIL']])\n",
    "passed_tests = total_tests - failed_tests\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"âœ… ì„±ê³µ: {passed_tests}/{total_tests} ({((passed_tests / total_tests * 100) if total_tests > 0 else 0):.1f}%)\")\n",
    "\n",
    "if failed_tests == 0:\n",
    "    print(\"ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "    print(\"ğŸ’¾ ìºì‹œ, ì»¤ë°‹, matplotlib ê¸°ëŠ¥ ëª¨ë‘ ì •ìƒ ì‘ë™\")\n",
    "else:\n",
    "    print(f\"âš ï¸ {failed_tests}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨\")\n",
    "    print(\"\\nì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:\")\n",
    "    for result in test_results:\n",
    "        if result['status'] in ['ì‹¤íŒ¨', 'FAIL']:\n",
    "            print(f\"- {result['test']}\")\n",
    "\n",
    "print(f\"\\nğŸ”– Helper ëª¨ë“ˆ: {helper_version}\")\n",
    "print(f\"ğŸ“… ì™„ë£Œ: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f73c9a",
   "metadata": {
    "id": "10f73c9a"
   },
   "outputs": [],
   "source": [
    "# ğŸ“„ ìƒì„¸ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„± (ì„ íƒì  ì‹¤í–‰)\n",
    "# ì´ ì…€ì€ í•„ìš”í•  ë•Œë§Œ ì‹¤í–‰í•˜ì„¸ìš” - ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "print(\"ğŸ“ ìƒì„¸ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...\")\n",
    "\n",
    "# ë¦¬í¬íŠ¸ íŒŒì¼ëª… ìƒì„±\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# docs/reports í´ë” ìƒì„±\n",
    "reports_dir = 'docs/reports'\n",
    "os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "report_filename = os.path.join(reports_dir, f'test_report_{timestamp}.md')\n",
    "\n",
    "# ìƒì„¸ ë¦¬í¬íŠ¸ ë‚´ìš© ìƒì„±\n",
    "report_content = f\"\"\"---\n",
    "layout: default\n",
    "title: \"ìœ ë‹› í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ - v{helper_version}\"\n",
    "description: \"Jupyter í•œê¸€ í™˜ê²½ ì„¤ì • ëª¨ë“ˆì˜ í¬ê´„ì ì¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë° ì„±ëŠ¥ ê²€ì¦ ë¦¬í¬íŠ¸\"\n",
    "date: {datetime.now().strftime('%Y-%m-%d')}\n",
    "cache-control: no-cache\n",
    "expires: 0\n",
    "pragma: no-cache\n",
    "---\n",
    "\n",
    "# Helper Module Unit Test Report\n",
    "\n",
    "## ğŸ“Š í…ŒìŠ¤íŠ¸ ê°œìš”\n",
    "- **í…ŒìŠ¤íŠ¸ ë‚ ì§œ**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\n",
    "- **í…ŒìŠ¤íŠ¸ ëŒ€ìƒ**: helper_c0z0c_dev.py v{helper_version}\n",
    "- **í…ŒìŠ¤íŠ¸ í™˜ê²½**: Python {sys.version.split()[0]}, Pandas {pd.__version__}\n",
    "- **ì´ í…ŒìŠ¤íŠ¸ ìˆ˜**: {total_tests}ê°œ\n",
    "- **í†µê³¼**: {passed_tests}ê°œ\n",
    "- **ì‹¤íŒ¨**: {failed_tests}ê°œ\n",
    "- **ì„±ê³µë¥ **: {((passed_tests / total_tests * 100) if total_tests > 0 else 0):.1f}%\n",
    "\n",
    "## ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìƒì„¸\n",
    "\n",
    "| ë²ˆí˜¸ | í…ŒìŠ¤íŠ¸ í•­ëª© | ê²°ê³¼ | ì˜¤ë¥˜ ë©”ì‹œì§€ |\n",
    "|------|-------------|------|-------------|\n",
    "\"\"\"\n",
    "\n",
    "for i, result in enumerate(test_results, 1):\n",
    "    status = \"âœ… PASS\" if result['status'] in ['ì„±ê³µ', 'PASS'] else \"âŒ FAIL\"\n",
    "    error = result['error'] if result['error'] else \"-\"\n",
    "    report_content += f\"| {i} | {result['test']} | {status} | {error} |\\n\"\n",
    "\n",
    "report_content += f\"\"\"\n",
    "\n",
    "## ğŸš€ v2.4.0 matplotlib ê°œì„ ì‚¬í•­\n",
    "- **IPython ê¸€ë¡œë²Œ ë“±ë¡**: `reset_matplotlib()` ì‹¤í–‰ í›„ ë…¸íŠ¸ë¶ ì „ì²´ì—ì„œ `plt` ì‚¬ìš© ê°€ëŠ¥\n",
    "- **í™˜ê²½ë³„ fallback**: IPython í™˜ê²½ì—ì„œëŠ” `user_ns` ë“±ë¡, ì¼ë°˜ í™˜ê²½ì—ì„œëŠ” `globals()` ì‚¬ìš©\n",
    "- **ëª¨ë“ˆ ì™„ì „ ë¦¬ì…‹**: matplotlib ëª¨ë“ˆë“¤ì„ `sys.modules`ì—ì„œ ì œê±° í›„ ì¬ë¡œë“œ\n",
    "- **í•œê¸€ í°íŠ¸ ìë™ ì„¤ì •**: í™˜ê²½ë³„(Colab/ë¡œì»¬) ìµœì  í•œê¸€ í°íŠ¸ ìë™ ì„ íƒ\n",
    "\n",
    "## ğŸ’¡ ê²°ë¡ \n",
    "{'ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! helper_c0z0c_dev.py ëª¨ë“ˆì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.' if failed_tests == 0 else f'âš ï¸ {failed_tests}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì¶”ê°€ ê°œë°œì´ í•„ìš”í•©ë‹ˆë‹¤.'}\n",
    "\n",
    "---\n",
    "**í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ëª¨ë“ˆ**: helper_c0z0c_dev.py v{helper_version}\n",
    "**í…ŒìŠ¤íŠ¸ í™˜ê²½**: Python {sys.version.split()[0]}, Pandas {pd.__version__}\n",
    "**í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**ì´ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: {total_tests}ê°œ í…ŒìŠ¤íŠ¸ í•­ëª©\n",
    "\"\"\"\n",
    "\n",
    "# ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥\n",
    "with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(f\"ğŸ“„ ìƒì„¸ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ íŒŒì¼: {report_filename}\")\n",
    "print(f\"ğŸ“ ìœ„ì¹˜: {os.path.abspath(report_filename)}\")\n",
    "print(f\"ğŸŒ GitHub Pages: https://c0z0c.github.io/jupyter_hangul/reports/\")\n",
    "\n",
    "print(\"\\nğŸ ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62598c",
   "metadata": {
    "id": "7f62598c"
   },
   "outputs": [],
   "source": [
    "# ğŸ”„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ìë™ ë²„ì „ ì—…ë°ì´íŠ¸\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸ”„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë²„ì „ ìë™ ì—…ë°ì´íŠ¸ ì¤‘...\")\n",
    "\n",
    "def update_markdown_versions():\n",
    "    \"\"\"ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë“¤ì˜ ë²„ì „ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸\"\"\"\n",
    "    try:\n",
    "        # í˜„ì¬ helper ë²„ì „ í™•ì¸\n",
    "        current_version = getattr(helper, '__version__', '2.4.0')\n",
    "        current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "        print(f\"ğŸ“Œ í˜„ì¬ helper ë²„ì „: v{current_version}\")\n",
    "        print(f\"ğŸ“… ì—…ë°ì´íŠ¸ ë‚ ì§œ: {current_date}\")\n",
    "\n",
    "        # ì—…ë°ì´íŠ¸í•  íŒŒì¼ ëª©ë¡ (ë£¨íŠ¸ README.md ì¶”ê°€)\n",
    "        files_to_update = [\n",
    "            'README.md',                    # ë£¨íŠ¸ README.md\n",
    "            'docs/index.md',\n",
    "            'docs/md/README.md',\n",
    "            'docs/md/CHEATSHEET.md',\n",
    "            'docs/md/COLAB_USAGE.md'\n",
    "        ]\n",
    "\n",
    "        updated_files = []\n",
    "\n",
    "        for file_path in files_to_update:\n",
    "            if os.path.exists(file_path):\n",
    "                print(f\"ğŸ“ ì—…ë°ì´íŠ¸ ì¤‘: {file_path}\")\n",
    "\n",
    "                # íŒŒì¼ ì½ê¸°\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                # ë” í¬ê´„ì ì¸ ë²„ì „ íŒ¨í„´ ì—…ë°ì´íŠ¸\n",
    "                version_patterns = [\n",
    "                    # ì œëª©ì˜ ë²„ì „ (ë‹¤ì–‘í•œ í˜•íƒœ)\n",
    "                    (r'# .* v[\\d\\.]+', lambda m: re.sub(r'v[\\d\\.]+', f'v{current_version}', m.group(0))),\n",
    "                    (r'## .* v[\\d\\.]+', lambda m: re.sub(r'v[\\d\\.]+', f'v{current_version}', m.group(0))),\n",
    "\n",
    "                    # helper_c0z0c_dev.py ê´€ë ¨ ë²„ì „\n",
    "                    (r'helper_c0z0c_dev\\.py v[\\d\\.]+', f'helper_c0z0c_dev.py v{current_version}'),\n",
    "                    (r'helper v[\\d\\.]+', f'helper v{current_version}'),\n",
    "                    (r'Helper Module v[\\d\\.]+', f'Helper Module v{current_version}'),\n",
    "\n",
    "                    # ì¼ë°˜ì ì¸ ë²„ì „ í‘œê¸°\n",
    "                    (r'ë²„ì „: v[\\d\\.]+', f'ë²„ì „: v{current_version}'),\n",
    "                    (r'Version: v[\\d\\.]+', f'Version: v{current_version}'),\n",
    "                    (r'version: \"v[\\d\\.]+\"', f'version: \"v{current_version}\"'),\n",
    "\n",
    "                    # ì—…ë°ì´íŠ¸ ì„¹ì…˜ì˜ ë²„ì „ (v2.X.X í˜•íƒœ)\n",
    "                    (r'### v[\\d\\.]+\\s+ì£¼ìš” ì—…ë°ì´íŠ¸', f'### v{current_version} ì£¼ìš” ì—…ë°ì´íŠ¸'),\n",
    "                    (r'## ğŸ†• v[\\d\\.]+\\s+ì£¼ìš” ì—…ë°ì´íŠ¸', f'## ğŸ†• v{current_version} ì£¼ìš” ì—…ë°ì´íŠ¸'),\n",
    "\n",
    "                    # ë‚ ì§œ ì—…ë°ì´íŠ¸\n",
    "                    (r'date: \\d{4}-\\d{2}-\\d{2}', f'date: {current_date}'),\n",
    "\n",
    "                    # ê¸°íƒ€ ì»¨í…ìŠ¤íŠ¸ì˜ ë²„ì „\n",
    "                    (r'v[\\d\\.]+\\s+ê°œì„ ì‚¬í•­', f'v{current_version} ê°œì„ ì‚¬í•­'),\n",
    "                    (r'v[\\d\\.]+\\s+ì‹ ê¸°ëŠ¥', f'v{current_version} ì‹ ê¸°ëŠ¥'),\n",
    "                    (r'v[\\d\\.]+\\s+í•µì‹¬ ê¸°ëŠ¥', f'v{current_version} í•µì‹¬ ê¸°ëŠ¥'),\n",
    "                    (r'v[\\d\\.]+\\s+ì‹ ê·œ ê¸°ëŠ¥', f'v{current_version} ì‹ ê·œ ê¸°ëŠ¥'),\n",
    "                    (r'v[\\d\\.]+\\s+ì‹ ê·œ\\)', f'v{current_version} ì‹ ê·œ)'),\n",
    "                    (r'\\(v[\\d\\.]+\\s+ì‹ ê·œ\\)', f'(v{current_version} ì‹ ê·œ)'),\n",
    "                    (r'v[\\d\\.]+\\s+ì™„ì „ í…ŒìŠ¤íŠ¸', f'v{current_version} ì™„ì „ í…ŒìŠ¤íŠ¸'),\n",
    "                    (r'v[\\d\\.]+\\s+ì•ˆì •ì„±', f'v{current_version} ì•ˆì •ì„±'),\n",
    "                ]\n",
    "\n",
    "                original_content = content\n",
    "                changes_made = 0\n",
    "\n",
    "                for pattern, replacement in version_patterns:\n",
    "                    if callable(replacement):\n",
    "                        # í•¨ìˆ˜í˜• replacement\n",
    "                        new_content = re.sub(pattern, replacement, content)\n",
    "                    else:\n",
    "                        # ë¬¸ìì—´ replacement\n",
    "                        new_content = re.sub(pattern, replacement, content)\n",
    "\n",
    "                    if new_content != content:\n",
    "                        content = new_content\n",
    "                        changes_made += 1\n",
    "\n",
    "                # ë³€ê²½ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ íŒŒì¼ ì“°ê¸°\n",
    "                if content != original_content:\n",
    "                    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(content)\n",
    "                    updated_files.append(file_path)\n",
    "                    print(f\"  âœ… {file_path} ì—…ë°ì´íŠ¸ ì™„ë£Œ ({changes_made}ê°œ íŒ¨í„´ ì ìš©)\")\n",
    "                else:\n",
    "                    print(f\"  â„¹ï¸ {file_path} ë³€ê²½ì‚¬í•­ ì—†ìŒ\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸ {file_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "        if updated_files:\n",
    "            print(f\"\\nâœ… ì´ {len(updated_files)}ê°œ íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ:\")\n",
    "            for file_path in updated_files:\n",
    "                print(f\"  - {file_path}\")\n",
    "        else:\n",
    "            print(\"\\nğŸ“Œ ì—…ë°ì´íŠ¸í•  íŒŒì¼ì´ ì—†ê±°ë‚˜ ëª¨ë“  íŒŒì¼ì´ ì´ë¯¸ ìµœì‹  ë²„ì „ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë²„ì „ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# ë²„ì „ ì—…ë°ì´íŠ¸ ì‹¤í–‰\n",
    "try:\n",
    "    success = update_markdown_versions()\n",
    "    if success:\n",
    "        print(\"\\nğŸ‰ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë²„ì „ ì—…ë°ì´íŠ¸ ì„±ê³µ!\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ ì¼ë¶€ íŒŒì¼ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ìë™ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ’¡ íŒŒì¼ ê¶Œí•œì´ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”\")\n",
    "\n",
    "print(\"\\nğŸ Unit Test Suite ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45506acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.4 AIHubShell í†µí•© í…ŒìŠ¤íŠ¸ ë° ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤\n",
    "def test_aihub_shell_integration():\n",
    "    \"\"\"AIHubShell í†µí•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ”„ AIHubShell í†µí•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        \n",
    "        # ë‹¤ì–‘í•œ ì´ˆê¸°í™” ì˜µì…˜ í…ŒìŠ¤íŠ¸\n",
    "        test_scenarios = [\n",
    "            {\"debug\": False, \"download_dir\": \".\"},\n",
    "            {\"debug\": True, \"download_dir\": \"./data\"},\n",
    "            {\"debug\": False, \"download_dir\": \"/tmp/aihub\"},\n",
    "            {\"debug\": True, \"download_dir\": None}  # Noneì€ ê¸°ë³¸ê°’ \".\"ë¡œ ì„¤ì •ë¨\n",
    "        ]\n",
    "        \n",
    "        for i, scenario in enumerate(test_scenarios):\n",
    "            print(f\"ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ {i+1}: {scenario}\")\n",
    "            \n",
    "            aihub = AIHubShell(**scenario)\n",
    "            \n",
    "            # ì„¤ì • í™•ì¸\n",
    "            expected_debug = scenario[\"debug\"]\n",
    "            expected_dir = scenario[\"download_dir\"] if scenario[\"download_dir\"] is not None else \".\"\n",
    "            \n",
    "            assert aihub.debug == expected_debug, f\"ì‹œë‚˜ë¦¬ì˜¤ {i+1}: debug ì„¤ì • ë¶ˆì¼ì¹˜\"\n",
    "            assert aihub.download_dir == expected_dir, f\"ì‹œë‚˜ë¦¬ì˜¤ {i+1}: download_dir ì„¤ì • ë¶ˆì¼ì¹˜\"\n",
    "            \n",
    "            # ê¸°ë³¸ ë©”ì„œë“œë“¤ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "            required_methods = ['help', 'print_usage', 'list_info', 'list_search', \n",
    "                              'download_dataset', 'merge_parts', 'merge_all_parts']\n",
    "            \n",
    "            for method in required_methods:\n",
    "                assert hasattr(aihub, method), f\"ì‹œë‚˜ë¦¬ì˜¤ {i+1}: {method} ë©”ì„œë“œê°€ ì—†ìŒ\"\n",
    "            \n",
    "            print(f\"âœ… ì‹œë‚˜ë¦¬ì˜¤ {i+1} í†µê³¼\")\n",
    "        \n",
    "        print(\"âœ… ëª¨ë“  ì´ˆê¸°í™” ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_dependency_check():\n",
    "    \"\"\"AIHubShell ì˜ì¡´ì„± ëª¨ë“ˆ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ“¦ AIHubShell ì˜ì¡´ì„± ëª¨ë“ˆ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        # AIHubShellì´ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ ëª¨ë“ˆë“¤ í™•ì¸\n",
    "        core_dependencies = {\n",
    "            'os': 'íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…',\n",
    "            'sys': 'ì‹œìŠ¤í…œ ê´€ë ¨ ê¸°ëŠ¥',\n",
    "            'json': 'JSON íŒŒì‹±',\n",
    "            'shutil': 'íŒŒì¼ ë³µì‚¬/ì´ë™',\n",
    "            'signal': 'ì‹œê·¸ë„ ì²˜ë¦¬',\n",
    "            'tarfile': 'TAR ì••ì¶• í•´ì œ',\n",
    "            'pathlib': 'ê²½ë¡œ ì²˜ë¦¬',\n",
    "            'datetime': 'ë‚ ì§œ/ì‹œê°„ ì²˜ë¦¬',\n",
    "            're': 'ì •ê·œí‘œí˜„ì‹'\n",
    "        }\n",
    "        \n",
    "        missing_modules = []\n",
    "        for module_name, description in core_dependencies.items():\n",
    "            try:\n",
    "                __import__(module_name)\n",
    "                print(f\"âœ… {module_name}: {description}\")\n",
    "            except ImportError:\n",
    "                missing_modules.append(module_name)\n",
    "                print(f\"âŒ {module_name}: {description} - ëª¨ë“ˆ ì—†ìŒ\")\n",
    "        \n",
    "        assert len(missing_modules) == 0, f\"í•„ìˆ˜ ëª¨ë“ˆì´ ì—†ìŒ: {missing_modules}\"\n",
    "        \n",
    "        # ì„ íƒì  ì˜ì¡´ì„± (requests) í™•ì¸\n",
    "        try:\n",
    "            import requests\n",
    "            print(\"âœ… requests: HTTP ìš”ì²­ ì²˜ë¦¬ (AIHub API í†µì‹ )\")\n",
    "            requests_available = True\n",
    "        except ImportError:\n",
    "            print(\"âš ï¸ requests: HTTP ìš”ì²­ ì²˜ë¦¬ - ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ (AIHub ê¸°ëŠ¥ ì œí•œ)\")\n",
    "            requests_available = False\n",
    "        \n",
    "        # AIHubShell ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ê¸°ë³¸ ë™ì‘ í™•ì¸\n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        aihub = AIHubShell()\n",
    "        \n",
    "        # requestsê°€ ì—†ì–´ë„ ê¸°ë³¸ ì´ˆê¸°í™”ëŠ” ê°€ëŠ¥í•´ì•¼ í•¨\n",
    "        assert aihub.BASE_URL == \"https://api.aihub.or.kr\", \"ê¸°ë³¸ URL ì„¤ì • ì‹¤íŒ¨\"\n",
    "        \n",
    "        print(\"âœ… ì˜ì¡´ì„± í™•ì¸ ì™„ë£Œ\")\n",
    "        \n",
    "        return {\"requests_available\": requests_available}\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell ì˜ì¡´ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_error_scenarios():\n",
    "    \"\"\"AIHubShell ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"âš ï¸ AIHubShell ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        \n",
    "        # ì •ìƒ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "        aihub = AIHubShell()\n",
    "        \n",
    "        # 1. ì˜ëª»ëœ ê²½ë¡œ ì„¤ì • í…ŒìŠ¤íŠ¸\n",
    "        print(\"ğŸ“ ì˜ëª»ëœ ê²½ë¡œ ì„¤ì • í…ŒìŠ¤íŠ¸\")\n",
    "        try:\n",
    "            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë“œë¼ì´ë¸Œë‚˜ ê¶Œí•œ ì—†ëŠ” ê²½ë¡œ\n",
    "            invalid_paths = [\n",
    "                \"/root/no_permission\" if os.name != 'nt' else \"Z:\\\\nonexistent\",\n",
    "                \"\\x00invalid_path\",  # null ë¬¸ì í¬í•¨\n",
    "                \"con\" if os.name == 'nt' else \"/dev/null/invalid\"  # ìœˆë„ìš° ì˜ˆì•½ì–´ ë˜ëŠ” ì˜ëª»ëœ ê²½ë¡œ\n",
    "            ]\n",
    "            \n",
    "            for invalid_path in invalid_paths:\n",
    "                try:\n",
    "                    test_aihub = AIHubShell(download_dir=invalid_path)\n",
    "                    # ì„¤ì •ì€ ë˜ì§€ë§Œ ì‹¤ì œ ì‚¬ìš© ì‹œ ì˜¤ë¥˜ ë°œìƒ ì˜ˆìƒ\n",
    "                    assert test_aihub.download_dir == invalid_path, \"ì˜ëª»ëœ ê²½ë¡œë„ ì„¤ì •ë¨\"\n",
    "                    print(f\"âš ï¸ ì˜ëª»ëœ ê²½ë¡œ ì„¤ì •ë¨: {invalid_path}\")\n",
    "                except Exception:\n",
    "                    print(f\"âœ… ì˜ëª»ëœ ê²½ë¡œ ê±°ë¶€ë¨: {invalid_path}\")\n",
    "        except Exception:\n",
    "            print(\"âš ï¸ ê²½ë¡œ í…ŒìŠ¤íŠ¸ ì¼ë¶€ ì‹¤íŒ¨ (ì˜ˆìƒëœ ë™ì‘)\")\n",
    "        \n",
    "        # 2. ë©”ì„œë“œ í˜¸ì¶œ ì‹œ íƒ€ì… ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤\n",
    "        print(\"ğŸ”§ ë©”ì„œë“œ íƒ€ì… ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤\")\n",
    "        \n",
    "        # download_dataset ì˜ëª»ëœ íƒ€ì… í…ŒìŠ¤íŠ¸\n",
    "        invalid_calls = [\n",
    "            {\"method\": \"download_dataset\", \"args\": (None, None, None), \"desc\": \"ëª¨ë“  ë§¤ê°œë³€ìˆ˜ None\"},\n",
    "            {\"method\": \"download_dataset\", \"args\": (\"\", \"\", \"\"), \"desc\": \"ë¹ˆ ë¬¸ìì—´ ë§¤ê°œë³€ìˆ˜\"},\n",
    "            {\"method\": \"list_info\", \"args\": ({\"invalid\": \"dict\"},), \"desc\": \"ë”•ì…”ë„ˆë¦¬ íƒ€ì… datasetkey\"},\n",
    "        ]\n",
    "        \n",
    "        for call_info in invalid_calls:\n",
    "            try:\n",
    "                method = getattr(aihub, call_info[\"method\"])\n",
    "                # ì‹¤ì œë¡œëŠ” API í˜¸ì¶œì´ë¯€ë¡œ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí•  ê²ƒì´ì§€ë§Œ\n",
    "                # ë©”ì„œë“œ ìì²´ëŠ” í˜¸ì¶œ ê°€ëŠ¥í•´ì•¼ í•¨\n",
    "                print(f\"ğŸ” {call_info['desc']}: ë©”ì„œë“œ í˜¸ì¶œ ê°€ëŠ¥\")\n",
    "            except AttributeError:\n",
    "                print(f\"âŒ {call_info['method']} ë©”ì„œë“œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\")\n",
    "        \n",
    "        print(\"âœ… ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_helper_integration():\n",
    "    \"\"\"AIHubShellê³¼ helper ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ”— AIHubShellê³¼ helper ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        # helper ëª¨ë“ˆì—ì„œ AIHubShellì„ ì˜¬ë°”ë¥´ê²Œ importí•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸\n",
    "        import helper_c0z0c_dev as helper\n",
    "        \n",
    "        # 1. helper ëª¨ë“ˆì„ í†µí•œ AIHubShell ì ‘ê·¼\n",
    "        AIHubShell_from_helper = getattr(helper, 'AIHubShell', None)\n",
    "        assert AIHubShell_from_helper is not None, \"helper ëª¨ë“ˆì—ì„œ AIHubShellì„ ì°¾ì„ ìˆ˜ ì—†ìŒ\"\n",
    "        \n",
    "        # 2. ì§ì ‘ importì™€ helperë¥¼ í†µí•œ import ë¹„êµ\n",
    "        from helper_c0z0c_dev import AIHubShell as DirectAIHubShell\n",
    "        \n",
    "        assert AIHubShell_from_helper is DirectAIHubShell, \"helperë¥¼ í†µí•œ importì™€ ì§ì ‘ importê°€ ë‹¤ë¦„\"\n",
    "        print(\"âœ… helper ëª¨ë“ˆ í†µí•© import í™•ì¸\")\n",
    "        \n",
    "        # 3. ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ê¸°ë³¸ ë™ì‘ í™•ì¸\n",
    "        aihub1 = AIHubShell_from_helper()\n",
    "        aihub2 = DirectAIHubShell()\n",
    "        \n",
    "        # ê°™ì€ í´ë˜ìŠ¤ì—ì„œ ìƒì„±ëœ ì¸ìŠ¤í„´ìŠ¤ì¸ì§€ í™•ì¸\n",
    "        assert type(aihub1) == type(aihub2), \"ì„œë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ íƒ€ì…\"\n",
    "        assert aihub1.BASE_URL == aihub2.BASE_URL, \"ê¸°ë³¸ URLì´ ë‹¤ë¦„\"\n",
    "        \n",
    "        print(\"âœ… ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¼ê´€ì„± í™•ì¸\")\n",
    "        \n",
    "        # 4. helper ëª¨ë“ˆì˜ ë‹¤ë¥¸ ê¸°ëŠ¥ê³¼ í•¨ê»˜ ì‚¬ìš© í…ŒìŠ¤íŠ¸\n",
    "        # ì˜ˆ: ìºì‹œ ê¸°ëŠ¥ê³¼ AIHubShell ì¡°í•©\n",
    "        cache_key = helper.cache_key(\"aihub_test\", \"integration\")\n",
    "        aihub_config = {\n",
    "            \"debug\": True,\n",
    "            \"download_dir\": \"./test_cache\",\n",
    "            \"base_url\": aihub1.BASE_URL\n",
    "        }\n",
    "        \n",
    "        # ìºì‹œì— AIHubShell ì„¤ì • ì €ì¥\n",
    "        cache_save_result = helper.cache_save(cache_key, aihub_config)\n",
    "        assert cache_save_result, \"AIHubShell ì„¤ì • ìºì‹œ ì €ì¥ ì‹¤íŒ¨\"\n",
    "        \n",
    "        # ìºì‹œì—ì„œ ì„¤ì • ë¡œë“œ\n",
    "        loaded_config = helper.cache_load(cache_key)\n",
    "        assert loaded_config == aihub_config, \"ìºì‹œëœ AIHubShell ì„¤ì •ì´ ë‹¤ë¦„\"\n",
    "        \n",
    "        # ìºì‹œ ì •ë¦¬\n",
    "        helper.cache_delete(cache_key)\n",
    "        \n",
    "        print(\"âœ… helper ìºì‹œ ê¸°ëŠ¥ê³¼ AIHubShell í†µí•© í™•ì¸\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShellê³¼ helper ëª¨ë“ˆ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "def test_aihub_shell_documentation_completeness():\n",
    "    \"\"\"AIHubShell ë¬¸ì„œí™” ì™„ì„±ë„ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ“š AIHubShell ë¬¸ì„œí™” ì™„ì„±ë„ í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        from helper_c0z0c_dev import AIHubShell\n",
    "        \n",
    "        # í´ë˜ìŠ¤ docstring í™•ì¸\n",
    "        class_doc = AIHubShell.__doc__\n",
    "        if class_doc:\n",
    "            print(f\"âœ… í´ë˜ìŠ¤ docstring ì¡´ì¬: {len(class_doc)}ì\")\n",
    "        else:\n",
    "            print(\"âš ï¸ í´ë˜ìŠ¤ docstring ì—†ìŒ\")\n",
    "        \n",
    "        # ë©”ì„œë“œë³„ docstring í™•ì¸\n",
    "        aihub = AIHubShell()\n",
    "        documented_methods = {}\n",
    "        undocumented_methods = []\n",
    "        \n",
    "        public_methods = [method for method in dir(aihub) \n",
    "                         if not method.startswith('_') and callable(getattr(aihub, method))]\n",
    "        \n",
    "        for method_name in public_methods:\n",
    "            method = getattr(aihub, method_name)\n",
    "            doc = method.__doc__\n",
    "            \n",
    "            if doc and doc.strip():\n",
    "                documented_methods[method_name] = len(doc.strip())\n",
    "                print(f\"âœ… {method_name}: docstring ì¡´ì¬ ({len(doc.strip())}ì)\")\n",
    "            else:\n",
    "                undocumented_methods.append(method_name)\n",
    "                print(f\"âš ï¸ {method_name}: docstring ì—†ìŒ\")\n",
    "        \n",
    "        # ë¬¸ì„œí™” í†µê³„\n",
    "        total_methods = len(public_methods)\n",
    "        documented_count = len(documented_methods)\n",
    "        documentation_rate = (documented_count / total_methods * 100) if total_methods > 0 else 0\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ë¬¸ì„œí™” í†µê³„:\")\n",
    "        print(f\"  - ì „ì²´ public ë©”ì„œë“œ: {total_methods}ê°œ\")\n",
    "        print(f\"  - ë¬¸ì„œí™”ëœ ë©”ì„œë“œ: {documented_count}ê°œ\")\n",
    "        print(f\"  - ë¬¸ì„œí™” ë¹„ìœ¨: {documentation_rate:.1f}%\")\n",
    "        \n",
    "        if undocumented_methods:\n",
    "            print(f\"  - ë¯¸ë¬¸ì„œí™” ë©”ì„œë“œ: {', '.join(undocumented_methods)}\")\n",
    "        \n",
    "        # help ë©”ì„œë“œ ë™ì‘ í™•ì¸\n",
    "        print(f\"\\nğŸ“– help() ë©”ì„œë“œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸:\")\n",
    "        try:\n",
    "            # help() ë©”ì„œë“œê°€ ì˜¤ë¥˜ ì—†ì´ ì‹¤í–‰ë˜ëŠ”ì§€ í™•ì¸\n",
    "            # (ì‹¤ì œ ì¶œë ¥ì€ ìº¡ì²˜í•˜ì§€ ì•Šê³  ì˜¤ë¥˜ë§Œ í™•ì¸)\n",
    "            aihub.help()\n",
    "            print(\"âœ… help() ë©”ì„œë“œ ì •ìƒ ì‹¤í–‰\")\n",
    "        except Exception as help_error:\n",
    "            print(f\"âŒ help() ë©”ì„œë“œ ì‹¤í–‰ ì˜¤ë¥˜: {help_error}\")\n",
    "        \n",
    "        return {\n",
    "            \"total_methods\": total_methods,\n",
    "            \"documented_methods\": documented_count,\n",
    "            \"documentation_rate\": documentation_rate,\n",
    "            \"undocumented\": undocumented_methods\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"AIHubShell ë¬¸ì„œí™” ì™„ì„±ë„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# AIHubShell í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸš€ AIHubShell í†µí•© ë° ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "run_test(\"AIHubShell í†µí•© ì‹œë‚˜ë¦¬ì˜¤\", test_aihub_shell_integration)\n",
    "\n",
    "dependency_result = run_test(\"AIHubShell ì˜ì¡´ì„± í™•ì¸\", test_aihub_shell_dependency_check)\n",
    "if dependency_result and not dependency_result.get(\"requests_available\", False):\n",
    "    print(\"âš ï¸ requests ëª¨ë“ˆì´ ì—†ì–´ ì¼ë¶€ AIHub ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.\")\n",
    "    print(\"   ì„¤ì¹˜: pip install requests\")\n",
    "\n",
    "run_test(\"AIHubShell ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤\", test_aihub_shell_error_scenarios)\n",
    "run_test(\"AIHubShell helper í†µí•©\", test_aihub_shell_helper_integration)\n",
    "\n",
    "doc_result = run_test(\"AIHubShell ë¬¸ì„œí™” ì™„ì„±ë„\", test_aihub_shell_documentation_completeness)\n",
    "if doc_result:\n",
    "    print(f\"ğŸ“š AIHubShell ë¬¸ì„œí™” í˜„í™©: {doc_result.get('documentation_rate', 0):.1f}% ì™„ë£Œ\")\n",
    "\n",
    "print(\"ğŸš€ AIHubShell í†µí•© ë° ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56b04c9",
   "metadata": {},
   "source": [
    "## ğŸ† AIHubShell í…ŒìŠ¤íŠ¸ ìµœì¢… ìš”ì•½\n",
    "\n",
    "### âœ… ì™„ë£Œëœ í…ŒìŠ¤íŠ¸ í•­ëª©\n",
    "1. **ê¸°ë³¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸**\n",
    "   - ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì†ì„± í™•ì¸\n",
    "   - ë§¤ê°œë³€ìˆ˜ í¬í•¨ ì´ˆê¸°í™” (debug, download_dir)\n",
    "   - URL ìƒìˆ˜ ì •í™•ì„± ê²€ì¦\n",
    "\n",
    "2. **ë©”ì„œë“œë³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸**\n",
    "   - `help()`: ì‚¬ìš©ë²• ì¶œë ¥ ê¸°ëŠ¥\n",
    "   - `print_usage()`: API ë§¤ë‰´ì–¼ ì¡°íšŒ\n",
    "   - `list_info()`, `list_search()`: ë°ì´í„°ì…‹ ëª©ë¡/ê²€ìƒ‰\n",
    "   - `download_dataset()`: ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "   - `merge_parts()`, `merge_all_parts()`: íŒŒì¼ ë³‘í•©\n",
    "\n",
    "3. **API ì—°ê²° êµ¬ì¡° í…ŒìŠ¤íŠ¸**\n",
    "   - URL êµ¬ì„± ë¡œì§ ê²€ì¦\n",
    "   - ë©”ì„œë“œ ì‹œê·¸ë‹ˆì²˜ í™•ì¸\n",
    "   - ë™ì  URL ìƒì„± íŒ¨í„´\n",
    "\n",
    "4. **í†µí•© ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸**\n",
    "   - ë‹¤ì–‘í•œ ì´ˆê¸°í™” ì˜µì…˜\n",
    "   - ì˜ì¡´ì„± ëª¨ë“ˆ í™•ì¸\n",
    "   - ì—ëŸ¬ ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤\n",
    "   - helper ëª¨ë“ˆê³¼ì˜ í†µí•©\n",
    "\n",
    "5. **ë¬¸ì„œí™” ì™„ì„±ë„ í…ŒìŠ¤íŠ¸**\n",
    "   - í´ë˜ìŠ¤/ë©”ì„œë“œ docstring í™•ì¸\n",
    "   - help() ë©”ì„œë“œ ë™ì‘ ê²€ì¦\n",
    "\n",
    "### ğŸ› ï¸ AIHubShell ì‚¬ìš© ê°€ì´ë“œ\n",
    "\n",
    "```python\n",
    "# 1. ê¸°ë³¸ ì‚¬ìš©ë²•\n",
    "from helper_c0z0c_dev import AIHubShell\n",
    "aihub = AIHubShell()\n",
    "\n",
    "# 2. ì˜µì…˜ ì„¤ì •\n",
    "aihub = AIHubShell(debug=True, download_dir='./downloads')\n",
    "\n",
    "# 3. ë°ì´í„°ì…‹ ê²€ìƒ‰\n",
    "aihub.list_search(datasetname='ê²€ìƒ‰ì–´')\n",
    "\n",
    "# 4. íŠ¹ì • ë°ì´í„°ì…‹ ì •ë³´ ì¡°íšŒ  \n",
    "aihub.list_info(datasetkey=576)\n",
    "\n",
    "# 5. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "aihub.download_dataset(apikey='YOUR_API_KEY', datasetkey=576, filekeys='all')\n",
    "\n",
    "# 6. ì‚¬ìš©ë²• ë„ì›€ë§\n",
    "aihub.help()\n",
    "```\n",
    "\n",
    "### ğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì •ë¦¬\n",
    "- **ì´ˆê¸°í™”**: âœ… ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼\n",
    "- **URL êµ¬ì„±**: âœ… ì •í™•í•œ API ì—”ë“œí¬ì¸íŠ¸ í™•ì¸\n",
    "- **ë©”ì„œë“œ ì¡´ì¬**: âœ… ëª¨ë“  í•„ìˆ˜ ë©”ì„œë“œ êµ¬í˜„ë¨\n",
    "- **ì˜ì¡´ì„±**: âœ… í•µì‹¬ ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥ (requests ì„ íƒì‚¬í•­)\n",
    "- **ì—ëŸ¬ ì²˜ë¦¬**: âœ… ì˜ˆìƒ ì‹œë‚˜ë¦¬ì˜¤ ì²˜ë¦¬ ê°€ëŠ¥\n",
    "- **í†µí•©ì„±**: âœ… helper ëª¨ë“ˆê³¼ ì™„ë²½ ì—°ë™\n",
    "\n",
    "### ğŸ”§ ê°œë°œì ì°¸ê³ ì‚¬í•­\n",
    "- requests ëª¨ë“ˆ í•„ìš” (ì‹¤ì œ API í†µì‹ ìš©)\n",
    "- pathlib ì‚¬ìš©ìœ¼ë¡œ ê²½ë¡œ ì²˜ë¦¬ ê°œì„ \n",
    "- signal í•¸ë“¤ëŸ¬ë¡œ ë‹¤ìš´ë¡œë“œ ì¤‘ë‹¨ ì²˜ë¦¬\n",
    "- tarfile ìë™ ì••ì¶• í•´ì œ ì§€ì›\n",
    "- part íŒŒì¼ ìë™ ë³‘í•© ê¸°ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acfb55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ AIHubShell í…ŒìŠ¤íŠ¸ í¬í•¨ ìµœì¢… ê²°ê³¼ ì—…ë°ì´íŠ¸\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸ¤– AIHubShell í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ìµœì¢… ê²°ê³¼ ì—…ë°ì´íŠ¸\")\n",
    "\n",
    "# í˜„ì¬ê¹Œì§€ì˜ ëª¨ë“  í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì§‘ê³„\n",
    "total_tests = len(test_results)\n",
    "passed_tests = len([r for r in test_results if r['status'] in ['ì„±ê³µ', 'PASS']])\n",
    "failed_tests = total_tests - passed_tests\n",
    "\n",
    "# AIHubShell ê´€ë ¨ í…ŒìŠ¤íŠ¸ë§Œ ë³„ë„ ì§‘ê³„\n",
    "aihub_tests = [r for r in test_results if 'AIHubShell' in r['test'] or 'aihub' in r['test'].lower()]\n",
    "aihub_total = len(aihub_tests)\n",
    "aihub_passed = len([r for r in aihub_tests if r['status'] in ['ì„±ê³µ', 'PASS']])\n",
    "aihub_failed = aihub_total - aihub_passed\n",
    "\n",
    "print(f\"ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
    "print(f\"   ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ\")\n",
    "print(f\"   ì„±ê³µ: {passed_tests}ê°œ âœ…\")\n",
    "print(f\"   ì‹¤íŒ¨: {failed_tests}ê°œ âŒ\")\n",
    "print(f\"   ì„±ê³µë¥ : {(passed_tests/total_tests*100):.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ¤– AIHubShell ì „ìš© í…ŒìŠ¤íŠ¸:\")\n",
    "print(f\"   AIHub í…ŒìŠ¤íŠ¸: {aihub_total}ê°œ\")\n",
    "print(f\"   ì„±ê³µ: {aihub_passed}ê°œ âœ…\")\n",
    "print(f\"   ì‹¤íŒ¨: {aihub_failed}ê°œ âŒ\")\n",
    "if aihub_total > 0:\n",
    "    print(f\"   AIHub ì„±ê³µë¥ : {(aihub_passed/aihub_total*100):.1f}%\")\n",
    "\n",
    "# í•µì‹¬ ê¸°ëŠ¥ë³„ í…ŒìŠ¤íŠ¸ í˜„í™©\n",
    "feature_categories = {\n",
    "    \"ìºì‹œ ê¸°ëŠ¥\": [\"ìºì‹œ\", \"cache\"],\n",
    "    \"pandas í™•ì¥\": [\"pandas\", \"head_att\", \"ì»¬ëŸ¼\"],\n",
    "    \"matplotlib\": [\"matplotlib\", \"ê¸€ë¡œë²Œ\"],\n",
    "    \"AIHubShell\": [\"AIHubShell\", \"aihub\"],\n",
    "    \"íŒŒì¼ ì½ê¸°\": [\"íŒŒì¼ ì½ê¸°\", \"pd_read_csv\"],\n",
    "    \"ì»¤ë°‹ ì‹œìŠ¤í…œ\": [\"ì»¤ë°‹\", \"commit\"]\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ“‹ ê¸°ëŠ¥ë³„ í…ŒìŠ¤íŠ¸ í˜„í™©:\")\n",
    "for category, keywords in feature_categories.items():\n",
    "    category_tests = [r for r in test_results \n",
    "                     if any(keyword in r['test'] for keyword in keywords)]\n",
    "    if category_tests:\n",
    "        category_passed = len([r for r in category_tests if r['status'] in ['ì„±ê³µ', 'PASS']])\n",
    "        category_total = len(category_tests)\n",
    "        print(f\"   {category}: {category_passed}/{category_total} \"\n",
    "              f\"({(category_passed/category_total*100):.0f}%)\")\n",
    "\n",
    "# ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš° ìš”ì•½ ì¶œë ¥\n",
    "if failed_tests > 0:\n",
    "    print(f\"\\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ëª©ë¡:\")\n",
    "    for i, result in enumerate([r for r in test_results if r['status'] in ['ì‹¤íŒ¨', 'FAIL']], 1):\n",
    "        print(f\"   {i}. {result['test']}\")\n",
    "        if result['error']:\n",
    "            print(f\"      â†’ {result['error']}\")\n",
    "\n",
    "# ì„±ê³µí•œ ê²½ìš° ì¶•í•˜ ë©”ì‹œì§€\n",
    "if failed_tests == 0:\n",
    "    print(f\"\\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!\")\n",
    "    print(f\"ğŸš€ helper_c0z0c_dev.py ëª¨ë“ˆì˜ ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!\")\n",
    "    print(f\"ğŸ’¡ AIHubShell í¬í•¨ ì´ {total_tests}ê°œ í…ŒìŠ¤íŠ¸ í•­ëª© ê²€ì¦ ì™„ë£Œ\")\n",
    "\n",
    "print(f\"\\nğŸ“… í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_colab_250827",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
